---
layout: post
title: PyTorch ç”Ÿæˆç½‘ç»œ
date: 2018-07-28
categories: blog
tags: [PyTorch,ç”Ÿæˆç½‘ç»œ]
description: PyTorch ç”Ÿæˆç½‘ç»œ
---
# ç”Ÿæˆç½‘ç»œ
æˆ‘ä»¬åœ¨å‰é¢ç« èŠ‚ä¸­çœ‹åˆ°çš„æ‰€æœ‰ç¤ºä¾‹éƒ½ä¾§é‡äºè§£å†³è¯¸å¦‚åˆ†ç±»æˆ–å›å½’ä¹‹ç±»çš„é—®é¢˜ã€‚ æœ¬ç« å¯¹äºç†è§£æ·±åº¦å­¦ä¹ å¦‚ä½•åœ¨æ— ç›‘ç£å­¦ä¹ ä¸­è§£å†³é—®é¢˜éå¸¸æœ‰æ„ä¹‰å’Œé‡è¦ã€‚
åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†åŸ¹è®­å­¦ä¹ å¦‚ä½•åˆ›å»ºçš„ç½‘ç»œï¼š

* åŸºäºå†…å®¹å’Œç‰¹å®šè‰ºæœ¯é£æ ¼çš„å›¾åƒï¼Œé€šå¸¸ç§°ä¸ºé£æ ¼è¿ç§»
* ä½¿ç”¨ç‰¹å®šç±»å‹çš„ç”Ÿæˆå¯¹æŠ—æ¥ç”Ÿæˆæ–°çš„é¢å­”ç½‘ç»œï¼ˆGANï¼‰
* ä½¿ç”¨è¯­è¨€å»ºæ¨¡ç”Ÿæˆæ–°æ–‡æœ¬


è¿™äº›æŠ€æœ¯æ„æˆäº†æ·±åº¦å­¦ä¹ é¢†åŸŸä¸­å‘ç”Ÿçš„å¤§å¤šæ•°é«˜çº§ç ”ç©¶çš„åŸºç¡€ã€‚ è¿›å…¥æ¯ä¸ªå­éƒ¨åˆ†çš„å…·ä½“ç»†èŠ‚ï¼Œä¾‹å¦‚GANå’Œè¯­è¨€å»ºæ¨¡ï¼Œéƒ½ä¸å±äºæœ¬ä¹¦çš„èŒƒå›´ï¼Œå› ä¸ºå®ƒä»¬æœ¬èº«åº”è¯¥æœ‰ä¸€æœ¬å•ç‹¬çš„ä¹¦ã€‚ æˆ‘ä»¬å°†äº†è§£å®ƒä»¬å¦‚ä½•å·¥ä½œä»¥åŠåœ¨PyTorchä¸­æ„å»ºå®ƒä»¬çš„è¿‡ç¨‹ã€‚

## ç¥ç»é£æ ¼è¿ç§»

æˆ‘ä»¬äººç±»å¯ä»¥ç”Ÿæˆå…·æœ‰ä¸åŒç²¾åº¦å’Œå¤æ‚ç¨‹åº¦çš„è‰ºæœ¯ä½œå“ã€‚è™½ç„¶åˆ›ä½œè‰ºæœ¯çš„è¿‡ç¨‹å¯èƒ½æ˜¯ä¸€ä¸ªéå¸¸å¤æ‚çš„è¿‡ç¨‹ï¼Œä½†å®ƒå¯ä»¥çœ‹ä½œæ˜¯ä¸¤ä¸ªæœ€é‡è¦å› ç´ çš„ç»“åˆï¼Œå³ç”»ä»€ä¹ˆå’Œå¦‚ä½•ç”»ã€‚ç»˜åˆ¶çš„å†…å®¹å—åˆ°æˆ‘ä»¬å‘¨å›´æ‰€çœ‹åˆ°çš„å†…å®¹çš„å¯å‘ï¼Œæˆ‘ä»¬ç»˜åˆ¶çš„å†…å®¹ä¹Ÿä¼šå—åˆ°æˆ‘ä»¬å‘¨å›´æŸäº›äº‹ç‰©çš„å½±å“ã€‚ä»è‰ºæœ¯å®¶çš„è§’åº¦æ¥çœ‹ï¼Œè¿™å¯èƒ½è¿‡äºç®€å•äº†ï¼Œä½†æ˜¯ä¸ºäº†ç†è§£æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨æ·±åº¦å­¦ä¹ ç®—æ³•åˆ›å»ºè‰ºæœ¯ä½œå“ï¼Œå®ƒéå¸¸æœ‰ç”¨ã€‚æˆ‘ä»¬å°†è®­ç»ƒæ·±åº¦å­¦ä¹ ç®—æ³•ä»ä¸€ä¸ªå›¾åƒä¸­è·å–å†…å®¹ï¼Œç„¶åæ ¹æ®ç‰¹å®šçš„è‰ºæœ¯é£æ ¼ç»˜åˆ¶å®ƒã€‚å¦‚æœæ‚¨æ˜¯è‰ºæœ¯å®¶æˆ–åˆ›æ„äº§ä¸šï¼Œæ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨è¿‘å¹´æ¥çš„ä»¤äººæƒŠå¹çš„ç ”ç©¶æ¥æ”¹è¿›è¿™ä¸€ç‚¹å¹¶åœ¨æ‚¨å·¥ä½œçš„é¢†åŸŸå†…åˆ›é€ ä¸€äº›å¾ˆé…·çš„ä¸œè¥¿ã€‚å³ä½¿æ‚¨ä¸æ˜¯ï¼Œå®ƒä»ç„¶ä¼šå‘æ‚¨ä»‹ç»ç”Ÿæˆæ¨¡å‹é¢†åŸŸï¼Œç½‘ç»œç”Ÿæˆçš„æ–°å†…å®¹ã€‚

è®©æˆ‘ä»¬äº†è§£åœ¨é«˜çº§åˆ«çš„ç¥ç»é£æ ¼è½¬ç§»ä¸­åšäº†ä»€ä¹ˆï¼Œç„¶åæ·±å…¥ç»†èŠ‚ï¼Œä»¥åŠæ„å»ºå®ƒæ‰€éœ€çš„PyTorchä»£ç ã€‚ æ ·å¼è½¬ç§»ç®—æ³•å…·æœ‰å†…å®¹å›¾åƒï¼ˆCï¼‰å’Œæ ·å¼å›¾åƒï¼ˆSï¼‰; è¯¥ç®—æ³•å¿…é¡»ç”Ÿæˆæ–°å›¾åƒï¼ˆOï¼‰ï¼Œå…¶å…·æœ‰æ¥è‡ªå†…å®¹å›¾åƒçš„å†…å®¹å’Œæ¥è‡ªæ ·å¼å›¾åƒçš„æ ·å¼ã€‚ è¿™ä¸ªåˆ›å»ºç¥ç»é£æ ¼è½¬ç§»çš„è¿‡ç¨‹ç”±Leon Gateså’Œå…¶ä»–äººåœ¨2015å¹´ï¼ˆA Neural Algorithm of Artistic styleï¼‰å¼•å…¥ã€‚ ä»¥ä¸‹æ˜¯æˆ‘ä»¬å°†ä½¿ç”¨çš„å†…å®¹å›¾åƒï¼ˆCï¼‰ï¼š
![](https://bennix.github.io/imgs/7_1.png)
ä»¥ä¸‹æ˜¯æ ·å¼å›¾åƒï¼ˆSï¼‰ï¼š
![](https://bennix.github.io/imgs/7_2.png)

è¿™æ˜¯æˆ‘ä»¬è¦ç”Ÿæˆçš„å›¾åƒï¼š
![](https://bennix.github.io/imgs/7_3.png)


```python
from torchvision.models import vgg19
from torch.autograd import Variable
from collections import OrderedDict
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from PIL import Image
%pylab inline

```

    Populating the interactive namespace from numpy and matplotlib


é£æ ¼è¿ç§»èƒŒåçš„æƒ³æ³•ä»ç†è§£å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å¦‚ä½•å·¥ä½œå˜å¾—ç›´è§‚ã€‚å½“CNNè¢«è®­ç»ƒç”¨äºå¯¹è±¡è¯†åˆ«æ—¶ï¼Œè®­ç»ƒå¥½çš„çš„CNNçš„æ—©æœŸå±‚å­¦ä¹ éå¸¸é€šç”¨çš„ä¿¡æ¯ï¼Œå¦‚çº¿ï¼Œæ›²çº¿å’Œå½¢çŠ¶ã€‚ CNNä¸­çš„æœ€åä¸€å±‚ä»å›¾åƒï¼ˆä¾‹å¦‚çœ¼ç›ï¼Œå»ºç­‘ç‰©å’Œæ ‘æœ¨ï¼‰æ•è·æ›´é«˜çº§åˆ«çš„æ¦‚å¿µã€‚å› æ­¤ï¼Œç›¸ä¼¼å›¾åƒçš„æœ€åå±‚çš„å€¼å¾€å¾€æ›´æ¥è¿‘ã€‚æˆ‘ä»¬é‡‡ç”¨ç›¸åŒçš„æ¦‚å¿µå¹¶å°†å…¶åº”ç”¨äºå†…å®¹ä¸¢å¤±ã€‚å†…å®¹å›¾åƒå’Œç”Ÿæˆçš„å›¾åƒçš„æœ€åä¸€å±‚åº”è¯¥ç›¸ä¼¼ï¼Œæˆ‘ä»¬ä½¿ç”¨å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰è®¡ç®—ç›¸ä¼¼åº¦ã€‚æˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬çš„ä¼˜åŒ–ç®—æ³•æ¥é™ä½æŸå¤±å€¼ã€‚

é€šå¸¸é€šè¿‡ç§°ä¸ºGramçŸ©é˜µçš„æŠ€æœ¯åœ¨CNNä¸­è·¨å¤šä¸ªå±‚æ•è·å›¾åƒçš„æ ·å¼ã€‚ GramçŸ©é˜µè®¡ç®—è·¨å¤šä¸ªå±‚æ•è·çš„è¦ç´ å›¾ä¹‹é—´çš„ç›¸å…³æ€§ã€‚ GramçŸ©é˜µç»™å‡ºäº†è®¡ç®—æ ·å¼çš„åº¦é‡ã€‚ç±»ä¼¼çš„æ ·å¼å›¾åƒå…·æœ‰ç±»ä¼¼äºGram çŸ©é˜µçš„å€¼ã€‚è¿˜ä½¿ç”¨æ ·å¼å›¾åƒçš„Gram çŸ©é˜µä¸ç”Ÿæˆçš„å›¾åƒä¹‹é—´çš„MSEæ¥è®¡ç®—æ ·å¼æŸå¤±ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨torchvisionæ¨¡å‹ä¸­æä¾›çš„é¢„è®­ç»ƒVGG19æ¨¡å‹ã€‚è®­ç»ƒæ ·å¼è½¬ç§»æ¨¡å‹æ‰€éœ€çš„æ­¥éª¤ä¸ä»»ä½•å…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹ç±»ä¼¼ï¼Œé™¤äº†è®¡ç®—æŸå¤±æ¯”åˆ†ç±»æˆ–å›å½’æ¨¡å‹æ›´å¤æ‚çš„äº‹å®ã€‚ç¥ç»é£æ ¼ç®—æ³•çš„è®­ç»ƒå¯ä»¥åˆ†è§£ä¸ºä»¥ä¸‹æ­¥éª¤ï¼š

1.åŠ è½½æ•°æ®ã€‚

2.åˆ›å»ºVGG19æ¨¡å‹ã€‚

3.å®šä¹‰å†…å®¹ä¸¢å¤±ã€‚

4.å®šä¹‰é£æ ¼æŸå¤±ã€‚

5.ä»VGGæ¨¡å‹ä¸­æå–è·¨å±‚çš„æŸå¤±ã€‚

6.åˆ›å»ºä¼˜åŒ–ç¨‹åºã€‚

7.è®­ç»ƒ - ç”Ÿæˆç±»ä¼¼äºå†…å®¹å›¾åƒçš„å›¾åƒï¼Œå¹¶ä¸”æ ·å¼ç±»ä¼¼äºé£æ ¼å½¢è±¡ã€‚

## åŠ è½½æ•°æ®

åŠ è½½æ•°æ®ç±»ä¼¼äºæˆ‘ä»¬åœ¨ç¬¬5ç« â€œè®¡ç®—æœºè§†è§‰çš„æ·±åº¦å­¦ä¹ â€ä¸­è§£å†³å›¾åƒåˆ†ç±»é—®é¢˜æ‰€çœ‹åˆ°çš„ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨é¢„è®­ç»ƒçš„VGGæ¨¡å‹ï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»ä½¿ç”¨è®­ç»ƒé¢„è®­ç»ƒæ¨¡å‹çš„ç›¸åŒå€¼æ¥æ ‡å‡†åŒ–å›¾åƒã€‚

ä»¥ä¸‹ä»£ç æ˜¾ç¤ºäº†æˆ‘ä»¬å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚ ä»£ç å¤§å¤šæ˜¯ä¸è¨€è‡ªæ˜çš„ï¼Œå› ä¸ºæˆ‘ä»¬å·²åœ¨å‰é¢çš„ç« èŠ‚ä¸­è¯¦ç»†è®¨è®ºè¿‡å®ƒï¼š


```python
imsize = 512 
is_cuda = torch.cuda.is_available()

prep = transforms.Compose([transforms.Resize(imsize),
                           transforms.ToTensor(),
                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to BGR
                           transforms.Normalize(mean=[0.40760392, 0.45795686, 0.48501961], #subtract imagenet mean
                                                std=[1,1,1]),
                           transforms.Lambda(lambda x: x.mul_(255)),
                          ])
postpa = transforms.Compose([transforms.Lambda(lambda x: x.mul_(1./255)),
                           transforms.Normalize(mean=[-0.40760392, -0.45795686, -0.48501961], #add imagenet mean
                                                std=[1,1,1]),
                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to RGB
                           ])
postpb = transforms.Compose([transforms.ToPILImage()])
def postp(tensor): # to clip results in the range [0,1]
    t = postpa(tensor)
    t[t>1] = 1    
    t[t<0] = 0
    img = postpb(t)
    return img
```

åœ¨æ­¤ä»£ç ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸‰ä¸ªåŠŸèƒ½ï¼Œprepæ‰§è¡Œæ‰€éœ€çš„æ‰€æœ‰é¢„å¤„ç†ï¼Œå¹¶ä½¿ç”¨ä¸VGGæ¨¡å‹è®­ç»ƒçš„æ ‡å‡†åŒ–ç›¸åŒçš„å€¼è¿›è¡Œæ ‡å‡†åŒ–ã€‚ æ¨¡å‹çš„è¾“å‡ºéœ€è¦å½’ä¸€åŒ–å›åŸå§‹å€¼; postpaå‡½æ•°æ‰§è¡Œæ‰€éœ€çš„å¤„ç†ã€‚ ç”Ÿæˆçš„æ¨¡å‹å¯èƒ½è¶…å‡ºäº†å¯æ¥å—å€¼çš„èŒƒå›´ï¼Œå¹¶ä¸”postpå‡½æ•°å°†æ‰€æœ‰å¤§äº1çš„å€¼é™åˆ¶ä¸ºå°äº0åˆ°0çš„å€¼ã€‚æœ€åï¼Œimage_loaderå‡½æ•°åŠ è½½å›¾åƒï¼Œåº”ç”¨é¢„å¤„ç†è½¬æ¢ï¼Œ å¹¶å°†å…¶è½¬æ¢ä¸ºå˜é‡ã€‚ ä»¥ä¸‹å‡½æ•°åŠ è½½æ ·å¼å’Œå†…å®¹å›¾åƒï¼š


```python
def image_loader(image_name):
    image = Image.open(image_name)
    image = Variable(prep(image))
    # fake batch dimension required to fit network's input dimensions
    image = image.unsqueeze(0)
    return image
```


```python
Image.open('Images/amrut1.jpg').resize((600,600))
```




![png](output_8_0.png)



æˆ‘ä»¬å°†ä½¿ç”¨ä¼˜åŒ–å™¨è°ƒæ•´opt_imgçš„å€¼ï¼Œä»¥ä½¿å›¾åƒæ›´æ¥è¿‘å†…å®¹å›¾åƒå’Œæ ·å¼å›¾åƒã€‚ å‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘ä»¬è¦æ±‚PyTorché€šè¿‡æåŠrequires_grad = Trueæ¥ç»´æŒæ¢¯åº¦æ¸å˜ã€‚æˆ‘ä»¬å¯ä»¥åˆ›å»ºå¸¦æœ‰å™ªå£°çš„å›¾åƒï¼ˆéšæœºæ•°ï¼‰ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ç›¸åŒçš„å†…å®¹å›¾åƒã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å†…å®¹å›¾åƒã€‚ ä»¥ä¸‹ä»£ç åˆ›å»ºå†…å®¹å›¾åƒï¼š


```python
style_img = image_loader("Images/vangogh_starry_night.jpg")
content_img = image_loader("Images/amrut1.jpg")
vgg = vgg19(pretrained=True).features
for param in vgg.parameters():
    param.requires_grad = False
if is_cuda:
    style_img = style_img.cuda()
    content_img = content_img.cuda()
    vgg = vgg.cuda()

opt_img = Variable(content_img.data.clone(),requires_grad=True)

```

## åˆ›å»ºVGGæ¨¡å‹

æˆ‘ä»¬å°†ä»torchvisions.modelsåŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ã€‚ æˆ‘ä»¬å°†ä»…ä½¿ç”¨æ­¤æ¨¡å‹æ¥æå–ç‰¹å¾ï¼Œå¹¶ä¸”PyTorch VGGæ¨¡å‹ä»¥è¿™æ ·çš„æ–¹å¼å®šä¹‰ï¼šæ‰€æœ‰å·ç§¯å—å°†åœ¨ç‰¹å¾æ¨¡å—ä¸­ï¼Œå¹¶ä¸”å®Œå…¨è¿æ¥æˆ–çº¿æ€§çš„å±‚åœ¨åˆ†ç±»å™¨æ¨¡å—ä¸­ã€‚ ç”±äºæˆ‘ä»¬ä¸ä¼šè®­ç»ƒVGGæ¨¡å‹ä¸­çš„ä»»ä½•æƒé‡æˆ–å‚æ•°ï¼Œæˆ‘ä»¬ä¹Ÿä¼šå†»ç»“æ¨¡å‹ã€‚ ä»¥ä¸Šä»£ç æ¼”ç¤ºäº†ç›¸åŒçš„å†…å®¹ã€‚åœ¨è¿™æ®µä»£ç ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªVGGæ¨¡å‹ï¼Œä»…ä½¿ç”¨å…¶å·ç§¯å—å¹¶å†»ç»“æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ï¼Œå› ä¸ºæˆ‘ä»¬ä»…å°†å…¶ç”¨äºæå–ç‰¹å¾ã€‚


```python


```

## é£æ ¼æŸå¤±
æ ·å¼æŸå¤±æ˜¯è·¨å¤šä¸ªå±‚è®¡ç®—çš„ã€‚ æ ·å¼ä¸¢å¤±æ˜¯ä¸ºæ¯ä¸ªè¦ç´ å›¾ç”Ÿæˆçš„gram çŸ©é˜µçš„MSEã€‚ gram çŸ©é˜µè¡¨ç¤ºå…¶ç‰¹å¾çš„ç›¸å…³å€¼ã€‚ è®©æˆ‘ä»¬é€šè¿‡ä½¿ç”¨ä¸‹å›¾å’Œä»£ç å®ç°æ¥ç†è§£gramçŸ©é˜µæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚
ä¸‹è¡¨æ˜¾ç¤ºäº†ç»´åº¦[2,3,3,3]çš„è¦ç´ å›¾çš„è¾“å‡ºï¼Œå…¶ä¸­åŒ…å«åˆ—å±æ€§Batch_sizeï¼ŒChannelså’ŒValuesï¼š
![](https://bennix.github.io/imgs/7_4.png)
ä¸ºäº†è®¡ç®—Gram çŸ©é˜µï¼Œæˆ‘ä»¬å°†æ¯ä¸ªé€šé“çš„æ‰€æœ‰å€¼å±•å¹³ï¼Œç„¶åé€šè¿‡ä¹˜ä»¥å…¶è½¬ç½®æ¥æ‰¾åˆ°ç›¸å…³æ€§ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š
![](https://bennix.github.io/imgs/7_5.png)
æˆ‘ä»¬æ‰€åšçš„å°±æ˜¯å°†æ¯ä¸ªé€šé“çš„æ‰€æœ‰å€¼å¹³å¦åŒ–ä¸ºå•ä¸ªå‘é‡æˆ–å¼ é‡ã€‚ ä»¥ä¸‹ä»£ç å®ç°äº†è¿™ä¸ªï¼š


```python
class GramMatrix(nn.Module):
    
    def forward(self,input):
        b,c,h,w = input.size()
        features = input.view(b,c,h*w)
        gram_matrix =  torch.bmm(features,features.transpose(1,2))
        gram_matrix.div_(h*w)
        return gram_matrix
```

æˆ‘ä»¬å°†GramMatrixå®ç°ä¸ºå…·æœ‰å‰å‘åŠŸèƒ½çš„å¦ä¸€ä¸ªPyTorchæ¨¡å—ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥åƒPyTorchä¸€æ ·ä½¿ç”¨å®ƒã€‚æˆ‘ä»¬ä»è¿™ä¸€è¡Œçš„è¾“å…¥å›¾åƒä¸­æå–ä¸åŒçš„ç»´åº¦ï¼š

```python
bï¼Œcï¼Œhï¼Œw = input.size()
```

è¿™é‡Œï¼Œ`b`è¡¨ç¤ºæ‰¹æ¬¡ï¼Œ`c`è¡¨ç¤ºè¿‡æ»¤å™¨æˆ–é€šé“ï¼Œ`h`è¡¨ç¤ºé«˜åº¦ï¼Œ`w`ä»£è¡¨å®½åº¦ã€‚åœ¨ä¸‹ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹ä»£ç æ¥ä¿æŒæ‰¹æ¬¡å’Œé€šé“å°ºå¯¸çš„å®Œæ•´æ€§ï¼Œå¹¶æ²¿é«˜åº¦å’Œå®½åº¦å°ºå¯¸å±•å¹³æ‰€æœ‰å€¼ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºï¼š
```python
features = input.view(bï¼Œcï¼Œh * w)
```

é€šè¿‡å°†å¹³å¦å€¼ä¸å…¶è½¬ç½®çŸ¢é‡ç›¸ä¹˜æ¥è®¡ç®—å…‹çŸ©é˜µã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨PyTorchæ‰¹å¤„ç†çŸ©é˜µä¹˜æ³•å‡½æ•°æ¥å®ç°ï¼Œè¯¥å‡½æ•°ä»¥torch.bmmï¼ˆï¼‰çš„å½¢å¼æä¾›ï¼Œå¦‚ä¸‹é¢çš„ä»£ç æ‰€ç¤ºï¼š
```python
gram_matrix = torch.bmm(featuresï¼Œfeatures.transpose(lï¼Œ2))
```

æˆ‘ä»¬é€šè¿‡å°†å®ƒé™¤ä»¥å…ƒç´ çš„æ•°é‡æ¥å®Œæˆå¯¹å…‹çŸ©é˜µçš„å€¼çš„æ ‡å‡†åŒ–ã€‚è¿™å¯ä»¥é˜²æ­¢å…·æœ‰å¤§é‡å€¼çš„ç‰¹å®šç‰¹å¾å›¾å æ®åˆ†æ•°ã€‚è®¡ç®—GramMatrixåï¼Œè®¡ç®—æ ·å¼ä¸¢å¤±å˜å¾—ç®€å•ï¼Œè¿™åœ¨ä»¥ä¸‹ä»£ç ä¸­å®ç°ï¼š


```python
class StyleLoss(nn.Module):
    
    def forward(self,inputs,targets):
        out = nn.MSELoss()(GramMatrix()(inputs),targets)
        return (out)
```

StyleLosså®ç°ä¸ºå¦ä¸€ä¸ªPyTorchå±‚ã€‚ å®ƒè®¡ç®—è¾“å…¥GramMatrixå€¼å’Œæ ·å¼å›¾åƒGramMatrixå€¼ä¹‹é—´çš„MSEã€‚

## æå–æŸå¤±
å°±åƒæˆ‘ä»¬ä½¿ç”¨ç¬¬5ç« â€œè®¡ç®—æœºè§†è§‰çš„æ·±åº¦å­¦ä¹ â€ä¸­çš„register_forward_hook()å‡½æ•°æå–å·ç§¯å±‚çš„æ¿€æ´»ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥æå–è®¡ç®—æ ·å¼ä¸¢å¤±å’Œå†…å®¹ä¸¢å¤±æ‰€éœ€çš„ä¸åŒå·ç§¯å±‚çš„æŸå¤±ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹çš„ä¸€ä¸ªåŒºåˆ«æ˜¯ï¼Œæˆ‘ä»¬éœ€è¦æå–å¤šä¸ªå±‚çš„è¾“å‡ºï¼Œè€Œä¸æ˜¯ä»ä¸€ä¸ªå±‚ä¸­æå–ã€‚ ä»¥ä¸‹ç±»é›†æˆäº†æ‰€éœ€çš„æ›´æ”¹ï¼š


```python
style_layers = [1,6,11,20,25]
content_layers = [21]
loss_layers = style_layers + content_layers

class LayerActivations():
    features=[]
    
    def __init__(self,model,layer_nums):
        
        self.hooks = []
        for layer_num in layer_nums:
            self.hooks.append(model[layer_num].register_forward_hook(self.hook_fn))
    
    def hook_fn(self,module,input,output):
        self.features.append(output)

    
    def remove(self):
        for hook in self.hooks:
            hook.remove()
        
```

`__init__`æ–¹æ³•é‡‡ç”¨æˆ‘ä»¬éœ€è¦è°ƒç”¨`register_forward_hook`æ–¹æ³•çš„æ¨¡å‹ä»¥åŠæˆ‘ä»¬éœ€è¦æå–è¾“å‡ºçš„å±‚æ•°ã€‚ `__init__`æ–¹æ³•ä¸­çš„forå¾ªç¯éå†å±‚æ•°å¹¶æ³¨å†Œæå–è¾“å‡ºæ‰€éœ€çš„å‰å‘é’©å­ã€‚
ä¼ é€’ç»™`register_forward_hook`æ–¹æ³•çš„`hook_fn`ä¹‹åç”±PyTorchè°ƒç”¨
`hook_fn`å‡½æ•°æ³¨å†Œçš„å±‚ã€‚ åœ¨å‡½æ•°å†…éƒ¨ï¼Œæˆ‘ä»¬æ•è·è¾“å‡ºå¹¶å°†å…¶å­˜å‚¨åœ¨`features`æ•°ç»„ä¸­ã€‚

å½“æˆ‘ä»¬ä¸æƒ³æ•è·è¾“å‡ºæ—¶ï¼Œæˆ‘ä»¬éœ€è¦è°ƒç”¨ä¸€æ¬¡removeå‡½æ•°ã€‚å¿˜è®°è°ƒç”¨removeæ–¹æ³•å¯èƒ½ä¼šå¯¼è‡´å†…å­˜ä¸è¶³å¼‚å¸¸è¾“å‡ºç´¯ç§¯ã€‚

è®©æˆ‘ä»¬ç¼–å†™å¦ä¸€ä¸ªå®ç”¨å‡½æ•°ï¼Œå®ƒå¯ä»¥æå–æ ·å¼å’Œæ‰€éœ€çš„è¾“å‡ºå†…å®¹å›¾ç‰‡ã€‚ ä»¥ä¸‹åŠŸèƒ½ä¹Ÿæ˜¯å¦‚æ­¤ï¼š


```python
def extract_layers(layers,img,model=None):
    la = LayerActivations(model,layers)
    #Clearing the cache 
    la.features = []
    out = model(img)
    la.remove()
    return la.features
```

åœ¨extract_layerså‡½æ•°å†…éƒ¨ï¼Œæˆ‘ä»¬é€šè¿‡ä¼ å…¥æ¨¡å‹å’Œå›¾å±‚ç¼–å·ä¸ºLayerActivationsç±»åˆ›å»ºå¯¹è±¡ã€‚ åŠŸèƒ½åˆ—è¡¨å¯èƒ½åŒ…å«å…ˆå‰è¿è¡Œçš„è¾“å‡ºï¼Œå› æ­¤æˆ‘ä»¬å°†é‡æ–°å¯åŠ¨åˆ°ç©ºåˆ—è¡¨ã€‚ ç„¶åæˆ‘ä»¬é€šè¿‡æ¨¡å‹ä¼ é€’å›¾åƒï¼Œæˆ‘ä»¬ä¸ä¼šä½¿ç”¨è¾“å‡ºã€‚ æˆ‘ä»¬å¯¹featuresæ•°ç»„ä¸­ç”Ÿæˆçš„è¾“å‡ºæ›´æ„Ÿå…´è¶£ã€‚ æˆ‘ä»¬è°ƒç”¨removeæ–¹æ³•ä»æ¨¡å‹ä¸­åˆ é™¤æ‰€æœ‰å·²æ³¨å†Œçš„é’©å­å¹¶è¿”å›åŠŸèƒ½ã€‚ ä¸€æ—¦æˆ‘ä»¬æå–ç›®æ ‡ï¼Œæˆ‘ä»¬éœ€è¦ä»åˆ›å»ºå®ƒä»¬çš„å›¾å½¢ä¸­åˆ†ç¦»è¾“å‡ºã€‚ è¯·è®°ä½ï¼Œæ‰€æœ‰è¿™äº›è¾“å‡ºéƒ½æ˜¯PyTorchå˜é‡ï¼Œå®ƒä»¬ä¿å­˜æœ‰å…³å¦‚ä½•åˆ›å»ºå®ƒä»¬çš„ä¿¡æ¯ã€‚ ä½†æ˜¯ï¼Œå¯¹äºæˆ‘ä»¬çš„æƒ…å†µï¼Œæˆ‘ä»¬åªå¯¹è¾“å‡ºå€¼è€Œä¸æ˜¯å›¾è¡¨æ„Ÿå…´è¶£ï¼Œå› ä¸ºæˆ‘ä»¬ä¸ä¼šæ›´æ–°æ ·å¼å›¾åƒæˆ–å†…å®¹å›¾åƒã€‚ ä»¥ä¸‹ä»£ç æ˜¾ç¤ºäº†æˆ‘ä»¬å¦‚ä½•æå–æ ·å¼å’Œå†…å®¹å›¾åƒæ‰€éœ€çš„ç›®æ ‡ï¼š


```python
content_targets = extract_layers(content_layers,content_img,model=vgg)
content_targets = [t.detach() for t in content_targets]
style_targets = extract_layers(style_layers,style_img,model=vgg)
style_targets = [GramMatrix()(t).detach() for t in style_targets]
targets = style_targets + content_targets
```

ä¸€æ—¦æˆ‘ä»¬åˆ†ç¦»äº†ï¼Œè®©æˆ‘ä»¬å°†æ‰€æœ‰ç›®æ ‡æ·»åŠ åˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­ã€‚

åœ¨è®¡ç®—æ ·å¼ä¸¢å¤±å’Œå†…å®¹ä¸¢å¤±æ—¶ï¼Œæˆ‘ä»¬ä¼ é€’äº†ä¸¤ä¸ªåä¸ºcontentçš„åˆ—è¡¨
å›¾å±‚å’Œæ ·å¼å›¾å±‚ã€‚ä¸åŒçš„å±‚é€‰æ‹©å°†å¯¹è´¨é‡äº§ç”Ÿå½±å“
å›¾åƒç”Ÿæˆã€‚è®©æˆ‘ä»¬é€‰æ‹©ä¸è®ºæ–‡ä½œè€…æåˆ°çš„ç›¸åŒçš„å±‚æ¬¡ã€‚ä»¥ä¸‹ä»£ç æ˜¾ç¤ºäº†æˆ‘ä»¬åœ¨æ­¤å¤„ä½¿ç”¨çš„å›¾å±‚é€‰æ‹©ï¼š

```python
style_layers = [1,6,11,20,25]
content_layers = [21]
loss_layers = style_layers + content_layers
```

ä¼˜åŒ–å™¨æœŸæœ›å•ä¸ªæ ‡é‡æ•°é‡æœ€å°åŒ–ã€‚ä¸ºäº†è·å¾—å•ä¸ªæ ‡é‡å€¼ï¼Œæˆ‘ä»¬æ€»ç»“äº†åˆ°è¾¾ä¸åŒå±‚çš„æ‰€æœ‰æŸå¤±ã€‚é€šå¸¸çš„åšæ³•æ˜¯å¯¹è¿™äº›æŸå¤±è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¹¶å†æ¬¡é€‰æ‹©ä¸GitHubå­˜å‚¨åº“ä¸­çš„æ–‡ä»¶å®ç°ä¸­ä½¿ç”¨çš„ç›¸åŒæƒé‡ï¼ˆhttps://github.com/leongatys/PytorchNeuralstyleTransfer ï¼‰ã€‚æˆ‘ä»¬çš„å®ç°æ˜¯ä½œè€…å®ç°çš„ç•¥å¾®ä¿®æ”¹ç‰ˆæœ¬ã€‚ä»¥ä¸‹ä»£ç æè¿°äº†æ‰€ä½¿ç”¨çš„æƒé‡ï¼Œè¿™äº›æƒé‡æ˜¯é€šè¿‡æ‰€é€‰å±‚ä¸­çš„è¿‡æ»¤å™¨æ•°é‡è®¡ç®—å¾—å‡ºçš„ï¼š


```python
#these are good weights settings:
style_weights = [1e3/n**2 for n in [64,128,256,512,512]]
content_weights = [1e0]
weights = style_weights + content_weights
```

ä¸ºäº†ä½¿å…¶å¯è§†åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥æ‰“å°VGGå›¾å±‚ã€‚ èŠ±ä¸€ç‚¹æ—¶é—´è§‚å¯Ÿæˆ‘ä»¬æ­£åœ¨æŠ½å–çš„å›¾å±‚ï¼Œæ‚¨å¯ä»¥å°è¯•ä¸åŒçš„å›¾å±‚ç»„åˆã€‚ æˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹ä»£ç æ‰“å°VGGå›¾å±‚ï¼š


```python
print(vgg)
```

    Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (6): ReLU(inplace)
      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (8): ReLU(inplace)
      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (11): ReLU(inplace)
      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (13): ReLU(inplace)
      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (15): ReLU(inplace)
      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (17): ReLU(inplace)
      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (20): ReLU(inplace)
      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (22): ReLU(inplace)
      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (24): ReLU(inplace)
      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (26): ReLU(inplace)
      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (29): ReLU(inplace)
      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (31): ReLU(inplace)
      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (33): ReLU(inplace)
      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (35): ReLU(inplace)
      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )


## ä¸ºæ¯ä¸ªå±‚åˆ›å»ºæŸå¤±å‡½æ•°

æˆ‘ä»¬å·²ç»å°†æŸå¤±å‡½æ•°å®šä¹‰ä¸ºPyTorchå±‚ã€‚ å› æ­¤ï¼Œè®©æˆ‘ä»¬ä¸ºä¸åŒçš„é£æ ¼æŸå¤±å’Œå†…å®¹æŸå¤±åˆ›å»ºæŸå¤±å±‚ã€‚ loss_fnsæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«ä¸€å †æ ·å¼ä¸¢å¤±å¯¹è±¡å’ŒåŸºäºæ‰€åˆ›å»ºæ•°ç»„é•¿åº¦çš„å†…å®¹ä¸¢å¤±å¯¹è±¡ã€‚ä»¥ä¸‹ä»£ç å®šä¹‰äº†è¯¥å‡½æ•°ï¼š


```python
loss_fns = [StyleLoss()] * len(style_layers) + [nn.MSELoss()] * len(content_layers)
if is_cuda:
    loss_fns = [fn.cuda() for fn in loss_fns]
```

## åˆ›å»ºä¼˜åŒ–ç¨‹åº
é€šå¸¸ï¼Œæˆ‘ä»¬ä¼ é€’åƒVGGè¿™æ ·çš„ç½‘ç»œå‚æ•°è¿›è¡Œè®­ç»ƒã€‚ ä½†æ˜¯ï¼Œåœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨VGGæ¨¡å‹ä½œä¸ºç‰¹å¾æå–å™¨ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬æ— æ³•ä¼ é€’VGGå‚æ•°ã€‚ åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä»…æä¾›æˆ‘ä»¬å°†ä¼˜åŒ–çš„opt_imgå˜é‡çš„å‚æ•°ï¼Œä»¥ä½¿å›¾åƒå…·æœ‰æ‰€éœ€çš„å†…å®¹å’Œæ ·å¼ã€‚ ä»¥ä¸‹ä»£ç åˆ›å»ºä¼˜åŒ–å…¶å€¼çš„ä¼˜åŒ–å™¨ï¼š


```python
optimizer = optim.LBFGS([opt_img])
```

ç°åœ¨æˆ‘ä»¬æœ‰äº†è®­ç»ƒæ‰€éœ€çš„æ‰€æœ‰ç»„ä»¶ã€‚

## è®­ç»ƒ

ä¸æˆ‘ä»¬è¿„ä»Šä¸ºæ­¢è®­ç»ƒçš„å…¶ä»–æ¨¡å‹ç›¸æ¯”ï¼Œè®­ç»ƒæ–¹æ³•ä¸åŒã€‚ åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—å¤šå±‚çš„æŸå¤±ï¼Œä»¥åŠæ¯æ¬¡ä¼˜åŒ–å™¨
è°ƒç”¨åï¼Œå®ƒå°†æ›´æ”¹è¾“å…¥å›¾åƒï¼Œä½¿å…¶å†…å®¹å’Œæ ·å¼æ¥è¿‘ç›®æ ‡å†…å®¹å’Œé£æ ¼ã€‚ è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹ç”¨äºè®­ç»ƒçš„ä»£ç ï¼Œç„¶åæˆ‘ä»¬å°†é€æ­¥ä»‹ç»
åŸ¹è®­çš„é‡è¦æ­¥éª¤ï¼š


```python

#run style transfer
max_iter = 500
show_iter = 50

n_iter=[0]

while n_iter[0] <= max_iter:

    def closure():
        optimizer.zero_grad()
        
        out = extract_layers(loss_layers,opt_img,model=vgg)
        layer_losses = [weights[a] * loss_fns[a](A, targets[a]) for a,A in enumerate(out)]
        loss = sum(layer_losses)
        loss.backward()
        n_iter[0]+=1
        #print loss
        if n_iter[0]%show_iter == (show_iter-1):
            print('Iteration: %d, loss: %f'%(n_iter[0]+1, loss.data.item()))

        return loss
    
    optimizer.step(closure)
    

```

    Iteration: 50, loss: 26043.576172
    Iteration: 100, loss: 13674.988281
    Iteration: 150, loss: 11287.914062
    Iteration: 200, loss: 10558.317383
    Iteration: 250, loss: 10203.455078
    Iteration: 300, loss: 10011.093750
    Iteration: 350, loss: 9884.095703
    Iteration: 400, loss: 9795.749023
    Iteration: 450, loss: 9725.958008
    Iteration: 500, loss: 9673.065430


æˆ‘ä»¬æ­£åœ¨è¿è¡Œ500æ¬¡è¿­ä»£çš„è®­ç»ƒå¾ªç¯ã€‚ å¯¹äºæ¯æ¬¡è¿­ä»£ï¼Œæˆ‘ä»¬ä½¿ç”¨extract_layerså‡½æ•°è®¡ç®—VGGæ¨¡å‹çš„ä¸åŒå±‚çš„è¾“å‡ºã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå”¯ä¸€æ”¹å˜çš„æ˜¯opt_imgçš„å€¼ï¼Œå®ƒå°†åŒ…å«æˆ‘ä»¬çš„æ ·å¼å›¾åƒã€‚ ä¸€æ—¦è®¡ç®—å‡ºè¾“å‡ºï¼Œæˆ‘ä»¬å°±ä¼šé€šè¿‡è¿­ä»£è¾“å‡ºå¹¶å°†å®ƒä»¬ä¸å„è‡ªçš„ç›®æ ‡ä¸€èµ·ä¼ é€’ç»™ç›¸åº”çš„æŸå¤±å‡½æ•°æ¥è®¡ç®—æŸå¤±ã€‚ æˆ‘ä»¬æ±‡æ€»æ‰€æœ‰æŸå¤±å¹¶è°ƒç”¨backwardå‡½æ•°ã€‚ åœ¨closureå‡½æ•°ç»“æŸæ—¶ï¼Œè¿”å›æŸå¤±ã€‚ è°ƒç”¨closureæ–¹æ³•ä»¥åŠmax_iterçš„optimizer.stepæ–¹æ³•ã€‚ å¦‚æœæ‚¨åœ¨GPUä¸Šè¿è¡Œï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ‰èƒ½è¿è¡Œ; å¦‚æœæ‚¨åœ¨CPUä¸Šè¿è¡Œï¼Œè¯·å°è¯•ç¼©å°å›¾åƒçš„å¤§å°ä»¥ä½¿å…¶è¿è¡Œå¾—æ›´å¿«ã€‚

è¿è¡Œ500ä¸ª epoch åï¼Œæˆ‘æœºå™¨ä¸Šç”Ÿæˆçš„å›¾åƒå¦‚ä¸‹æ‰€ç¤ºã€‚ å°è¯•ä¸åŒçš„å†…å®¹å’Œæ ·å¼ç»„åˆï¼Œä»¥ç”Ÿæˆæœ‰è¶£çš„å›¾åƒï¼š


```python
#display result
out_img_hr = postp(opt_img.data[0].cpu().squeeze())

imshow(out_img_hr)
gcf().set_size_inches(10,10)
```


![png](output_35_0.png)


åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œè®©æˆ‘ä»¬ç»§ç»­ä½¿ç”¨æ·±åº¦å·ç§¯ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆDCGANï¼‰ç”Ÿæˆå›¾åƒã€‚

#  ç”Ÿæˆå¯¹æŠ—æ€§ç½‘ç»œ

GANåœ¨è¿‡å»å‡ å¹´ä¸­å˜å¾—éå¸¸æµè¡Œã€‚æ¯å‘¨éƒ½ä¼šåœ¨GANåŒºåŸŸå–å¾—ä¸€äº›è¿›å±•ã€‚å®ƒå·²ç»æˆä¸ºæ·±åº¦å­¦ä¹ çš„é‡è¦å­é¢†åŸŸä¹‹ä¸€ï¼Œæ‹¥æœ‰ä¸€ä¸ªéå¸¸æ´»è·ƒçš„ç ”ç©¶ç¤¾åŒºã€‚ GANç”±Ian Goodfellowäº2014å¹´æ¨å‡º, GANé€šè¿‡è®­ç»ƒä¸¤ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆç§°ä¸ºç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨ï¼‰æ¥è§£å†³æ— ç›‘ç£å­¦ä¹ çš„é—®é¢˜ï¼Œè¿™ä¸¤ä¸ªç¥ç»ç½‘ç»œç›¸äº’ç«äº‰ã€‚åœ¨åŸ¹è®­è¿‡ç¨‹ä¸­ï¼Œä¸¤è€…æœ€ç»ˆéƒ½ä¼šåœ¨ä»–ä»¬æ‰§è¡Œçš„ä»»åŠ¡ä¸­å˜å¾—æ›´å¥½ã€‚

ä½¿ç”¨ä¼ªé€ è€…ï¼ˆç”Ÿæˆå™¨ï¼‰å’Œè­¦å¯Ÿï¼ˆé‰´åˆ«å™¨ï¼‰çš„æƒ…å†µå¯ä»¥ç›´è§‚åœ°ç†è§£GANã€‚æœ€åˆï¼Œä¼ªé€ è€…å‘è­¦æ–¹å±•ç¤ºå‡é’±ã€‚è­¦å¯Ÿè®¤ä¸ºå®ƒæ˜¯å‡çš„ï¼Œå¹¶å‘ä¼ªé€ è€…è§£é‡Šä¸ºä»€ä¹ˆå®ƒæ˜¯å‡çš„ã€‚ä¼ªé€ è€…æ ¹æ®æ”¶åˆ°çš„åé¦ˆåˆ¶ä½œæ–°çš„å‡é’±ã€‚è­¦æ–¹å‘ç°å®ƒæ˜¯å‡çš„ï¼Œå¹¶é€šçŸ¥ä¼ªé€ è€…ä¸ºä»€ä¹ˆæ˜¯å‡çš„ã€‚å®ƒé‡å¤äº†è¿™ä¹ˆå¤šæ¬¡ï¼Œç›´åˆ°ä¼ªé€ è€…èƒ½å¤Ÿä¼ªé€ è­¦å¯Ÿæ— æ³•è¯†åˆ«çš„å‡é’±ã€‚åœ¨GANåœºæ™¯ä¸­ï¼Œæˆ‘ä»¬æœ€ç»ˆå¾—åˆ°äº†ä¸€ä¸ªç”Ÿæˆä¼ªé€ å›¾åƒçš„ç”Ÿæˆå™¨ï¼Œè¿™äº›ä¼ªé€ å›¾åƒä¸çœŸå®å›¾åƒéå¸¸ç›¸ä¼¼ï¼Œå¹¶ä¸”åˆ†ç±»å™¨åœ¨è¯†åˆ«çœŸå®ç‰©ä½“ä¸­çš„ä¼ªé€ å“æ–¹é¢å˜å¾—éå¸¸æ£’ã€‚


```python
import os
from torchvision import datasets
from torch.utils.data import DataLoader
import torch.nn as nn
import torch
from torch.autograd import Variable
import torch.optim as optim
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
from PIL import Image
import torchvision.utils as vutils
%matplotlib inline
```

GANæ˜¯ä¼ªé€ ç½‘ç»œå’Œä¸“å®¶ç½‘ç»œçš„ç»„åˆï¼Œæ¯ä¸ªéƒ½ç»è¿‡è®­ç»ƒä»¥å‡»è´¥å¯¹æ–¹ã€‚ ç”Ÿæˆå™¨ç½‘ç»œå°†éšæœºå‘é‡ä½œä¸ºè¾“å…¥å¹¶ç”Ÿæˆåˆæˆå›¾åƒã€‚ é‰´åˆ«å™¨ç½‘ç»œè·å–è¾“å…¥å›¾åƒå¹¶é¢„æµ‹å›¾åƒæ˜¯çœŸå®çš„è¿˜æ˜¯å‡çš„ã€‚ æˆ‘ä»¬å°†é‰´åˆ«å™¨ç½‘ç»œä¼ é€’ä¸ºçœŸå®å›¾åƒæˆ–ä¼ªå›¾åƒã€‚

ç”Ÿæˆå™¨ç½‘ç»œç»è¿‡è®­ç»ƒä»¥äº§ç”Ÿå›¾åƒå¹¶æ¬ºéª—é‰´åˆ«å™¨ç½‘ç»œä½¿å…¶ç›¸ä¿¡å®ƒä»¬æ˜¯çœŸå®çš„ã€‚ ç”±äºæˆ‘ä»¬åœ¨è®­ç»ƒæ—¶ä¼ é€’åé¦ˆï¼Œå› æ­¤é‰´åˆ«å™¨ç½‘ç»œä¹Ÿåœ¨ä¸è¢«æ„šå¼„æ—¶ä¸æ–­æ”¹è¿›ã€‚ å°½ç®¡GANçš„ç†å¿µåœ¨ç†è®ºä¸Šå¬èµ·æ¥å¾ˆç®€å•ï¼Œä½†è®­ç»ƒå®é™…å·¥ä½œçš„GANæ¨¡å‹éå¸¸å›°éš¾ã€‚ è®­ç»ƒGANä¹Ÿå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºæœ‰ä¸¤ä¸ªéœ€è¦è®­ç»ƒçš„æ·±åº¦ç¥ç»ç½‘ç»œã€‚

>DCGANæ˜¯æ—©æœŸæ¨¡å‹ä¹‹ä¸€ï¼Œå®ƒæ¼”ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªè‡ªå­¦ä¹ å¹¶ç”Ÿæˆæœ‰æ„ä¹‰å›¾åƒçš„GANæ¨¡å‹ã€‚ æ‚¨å¯ä»¥åœ¨æ­¤å¤„äº†è§£æ›´å¤šä¿¡æ¯ï¼š
https://arxiv.org/pdf/1511.06434.pdf

ä¸‹å›¾æ˜¾ç¤ºäº†GANçš„ä½“ç³»ç»“æ„
![](https://bennix.github.io/imgs/7_10.png)

æˆ‘ä»¬å°†ä»‹ç»è¿™ä¸ªä½“ç³»ç»“æ„çš„æ¯ä¸ªç»„ä»¶ï¼Œä»¥åŠå®ƒä»¬èƒŒåçš„ä¸€äº›åŸç†ï¼Œç„¶åæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­åœ¨PyTorchä¸­å®ç°ç›¸åŒçš„æµç¨‹ã€‚åˆ°å®æ–½ç»“æŸæ—¶ï¼Œæˆ‘ä»¬å°†äº†è§£DCGANçš„å·¥ä½œåŸç†ã€‚

## æ·±å·ç§¯GAN
åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†åŸºäºå‰é¢ä¿¡æ¯æ¡†ä¸­æåˆ°çš„DCGANï¼Œå®æ–½GANæ¶æ„è®­ç»ƒçš„ä¸åŒéƒ¨åˆ†ã€‚è®­ç»ƒDCGANçš„ä¸€äº›é‡è¦éƒ¨åˆ†åŒ…æ‹¬ï¼š

* ç”Ÿæˆå™¨ç½‘ç»œï¼Œå°†æŸäº›å›ºå®šç»´åº¦çš„æ½œåœ¨å‘é‡ï¼ˆæ•°å­—åˆ—è¡¨ï¼‰æ˜ å°„åˆ°æŸç§å½¢çŠ¶çš„å›¾åƒã€‚åœ¨æˆ‘ä»¬çš„å®ç°ä¸­ï¼Œå½¢çŠ¶æ˜¯ï¼ˆ3,64,64ï¼‰ã€‚
* é‰´åˆ«å™¨ç½‘ç»œï¼Œå®ƒå°†ç”Ÿæˆå™¨æˆ–å®é™…æ•°æ®é›†ç”Ÿæˆçš„å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶æ˜ å°„åˆ°è¯„ä¼°è¾“å…¥å›¾åƒæ˜¯çœŸå®è¿˜æ˜¯å‡çš„åˆ†æ•°ã€‚
* å®šä¹‰å‘ç”Ÿå™¨å’Œé‰´åˆ«å™¨çš„æŸè€—å‡½æ•°ã€‚
* å®šä¹‰ä¼˜åŒ–ç¨‹åºã€‚
* è®­ç»ƒGANã€‚

è®©æˆ‘ä»¬è¯¦ç»†æ¢è®¨è¿™äº›éƒ¨åˆ†ã€‚å®ç°åŸºäºä»£ç ï¼Œ
è¿™å¯ä»¥åœ¨PyTorchç¤ºä¾‹ä¸­æ‰¾åˆ°ï¼š
https://github.com/pytorch/examples/tree/master/dcgan

## è½½å…¥æ•°æ®


```python
img_size = 64
batch_size=64
lr = 0.0002
beta1 = 0.5
niter= 25
outf= 'output'

dataset = datasets.CIFAR10( root = 'data',download=True,
                       transform=transforms.Compose([
                           transforms.Resize(img_size),
                           transforms.ToTensor(),
                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                       ]))
dataloader = torch.utils.data.DataLoader(dataset, batch_size,
                                         shuffle=True)

```

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz


# å®šä¹‰ç”Ÿæˆå™¨ç½‘ç»œ

ç”Ÿæˆå™¨ç½‘ç»œé‡‡ç”¨å›ºå®šç»´åº¦çš„éšæœºå‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶å¯¹å…¶åº”ç”¨ä¸€ç»„è½¬ç½®å·ç§¯ï¼Œæ‰¹é‡å½’ä¸€åŒ–å’ŒReLuæ¿€æ´»ï¼Œå¹¶ç”Ÿæˆæ‰€éœ€å¤§å°çš„å›¾åƒã€‚ åœ¨ç ”ç©¶ç”Ÿæˆå™¨å®ç°ä¹‹å‰ï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹å®šä¹‰è½¬ç½®å·ç§¯å’Œæ‰¹é‡è§„èŒƒåŒ–ã€‚


```python
#Size of latnet vector
nz = 100
# Filter size of generator
ngf = 64
# Filter size of discriminator
ndf = 64
# Output image channels
nc = 3
```

# è½¬ç½®çš„å·ç§¯
è½¬ç½®çš„å·ç§¯ä¹Ÿç§°ä¸ºåˆ†æ•°è·¨è¶Šå·ç§¯ã€‚ å®ƒä»¬çš„å·¥ä½œæ–¹å¼ä¸å·ç§¯çš„å·¥ä½œæ–¹å¼ç›¸åã€‚ ç›´è§‚åœ°ï¼Œä»–ä»¬è¯•å›¾è®¡ç®—è¾“å…¥å‘é‡å¦‚ä½•æ˜ å°„åˆ°æ›´é«˜ç»´åº¦ã€‚ è®©æˆ‘ä»¬çœ‹çœ‹ä¸‹å›¾ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£å®ƒï¼š
![](https://bennix.github.io/imgs/7_11.png)

è¯¥å›¾æ˜¯ä»Theanoï¼ˆå¦ä¸€ç§æµè¡Œçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼‰æ–‡æ¡£ï¼ˆ http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html ï¼‰å¼•ç”¨çš„ã€‚ å¦‚æœæ‚¨æƒ³æ›´å¤šåœ°äº†è§£æœ‰å…³è·¨è¶Šå·ç§¯çš„å·¥ä½œæ–¹å¼ï¼Œæˆ‘å¼ºçƒˆå»ºè®®æ‚¨é˜…è¯»Theanoæ–‡æ¡£ä¸­çš„è¿™ç¯‡æ–‡ç« ã€‚ å¯¹æˆ‘ä»¬æ¥è¯´é‡è¦çš„æ˜¯ï¼Œå®ƒæœ‰åŠ©äºå°†å‘é‡è½¬æ¢ä¸ºæ‰€éœ€ç»´åº¦çš„å¼ é‡ï¼Œå¹¶ä¸”æˆ‘ä»¬å¯ä»¥é€šè¿‡åå‘ä¼ æ’­æ¥è®­ç»ƒå†…æ ¸çš„å€¼ã€‚

## æ‰¹é‡æ ‡å‡†åŒ–
æˆ‘ä»¬å·²ç»è§‚å¯Ÿè¿‡å‡ æ¬¡æ‰€æœ‰ä¼ é€’ç»™æœºå™¨å­¦ä¹ æˆ–æ·±åº¦å­¦ä¹ ç®—æ³•çš„ç‰¹æ€§éƒ½è¢«æ ‡å‡†åŒ–äº†; ä¹Ÿå°±æ˜¯è¯´ï¼Œé€šè¿‡ä»æ•°æ®ä¸­å‡å»å¹³å‡å€¼ï¼Œç‰¹å¾å€¼ä»¥é›¶ä¸ºä¸­å¿ƒï¼Œå¹¶é€šè¿‡å°†æ•°æ®é™¤ä»¥å…¶æ ‡å‡†åå·®ç»™å‡ºæ•°æ®å•ä½æ ‡å‡†åå·®ã€‚ æˆ‘ä»¬é€šå¸¸ä¼šä½¿ç”¨PyTorch torchvision.Normalizeæ–¹æ³•æ¥å®Œæˆæ­¤æ“ä½œã€‚ ä»¥ä¸‹ä»£ç æ˜¾ç¤ºäº†ä¸€ä¸ªç¤ºä¾‹ï¼š

```python
transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
```

åœ¨æˆ‘ä»¬çœ‹åˆ°çš„æ‰€æœ‰ä¾‹å­ä¸­ï¼Œæ•°æ®åœ¨è¿›å…¥ç¥ç»ç½‘ç»œä¹‹å‰å°±å·²ç»æ ‡å‡†åŒ–äº†; æ— æ³•ä¿è¯ä¸­é—´å±‚è·å¾—æ ‡å‡†åŒ–è¾“å…¥ã€‚ ä¸‹å›¾æ˜¾ç¤ºäº†ç¥ç»ç½‘ç»œä¸­çš„ä¸­é—´å±‚å¦‚ä½•æ— æ³•è·å¾—è§„èŒƒåŒ–æ•°æ®ï¼š
![](https://bennix.github.io/imgs/7_12.png)



æ‰¹é‡æ ‡å‡†åŒ–çš„ä½œç”¨ç±»ä¼¼äºä¸­é—´å‡½æ•°ï¼Œæˆ–è€…å½“è®­ç»ƒæœŸé—´å‡å€¼å’Œæ–¹å·®éšæ—¶é—´å˜åŒ–æ—¶å¯¹ä¸­é—´æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–çš„å±‚ã€‚ æ‰¹é‡æ ‡å‡†åŒ–ç”±Ioffeå’ŒSzegedyäº2015å¹´å¼•å…¥ï¼ˆhttps://arxiv.org/abs/1502.03167 ï¼‰ã€‚ æ‰¹é‡æ ‡å‡†åŒ–åœ¨è®­ç»ƒå’ŒéªŒè¯æˆ–æµ‹è¯•æœŸé—´è¡¨ç°ä¸åŒã€‚ åœ¨è®­ç»ƒæœŸé—´ï¼Œè®¡ç®—æ‰¹æ¬¡ä¸­æ•°æ®çš„å‡å€¼å’Œæ–¹å·®ã€‚å¯¹äºéªŒè¯å’Œæµ‹è¯•ï¼Œä½¿ç”¨å…¨å±€å€¼ã€‚ æˆ‘ä»¬éœ€è¦ç†è§£çš„æ˜¯ï¼Œå®ƒä½¿ç”¨å®ƒæ¥è§„èŒƒåŒ–ä¸­é—´æ•°æ®ã€‚ 

ä½¿ç”¨æ‰¹é‡æ ‡å‡†åŒ–çš„ä¸€äº›å…³é”®ä¼˜åŠ¿æ˜¯ï¼š
* æ”¹å–„ç½‘ç»œä¸­çš„æ¢¯åº¦æµï¼Œä»è€Œå¸®åŠ©æˆ‘ä»¬æ„å»ºæ›´æ·±å…¥çš„ç½‘ç»œ
* å…è®¸æ›´é«˜çš„å­¦ä¹ ç‡
* å‡å°‘åˆå§‹åŒ–çš„å¼ºä¾èµ–æ€§
* ä½œä¸ºæ­£è§„åŒ–çš„ä¸€ç§å½¢å¼ï¼Œå‡å°‘äº†dropoutçš„ä¾èµ–æ€§

å¤§å¤šæ•°ç°ä»£ä½“ç³»ç»“æ„ï¼ˆå¦‚ResNetå’ŒInceptionï¼‰åœ¨å…¶ä½“ç³»ç»“æ„ä¸­å¹¿æ³›ä½¿ç”¨æ‰¹é‡æ ‡å‡†åŒ–ã€‚ æ‰¹é‡æ ‡å‡†åŒ–å±‚åœ¨å·ç§¯å±‚æˆ–çº¿æ€§/å®Œå…¨è¿æ¥å±‚ä¹‹åå¼•å…¥ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![](https://bennix.github.io/imgs/7_13.png)

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å¯¹ç”Ÿæˆå™¨ç½‘ç»œçš„å…³é”®ç»„ä»¶æœ‰äº†ç›´è§‚çš„äº†è§£ã€‚

# ç”Ÿæˆå™¨

è®©æˆ‘ä»¬å¿«é€ŸæŸ¥çœ‹ä»¥ä¸‹ç”Ÿæˆå™¨ç½‘ç»œä»£ç ï¼Œç„¶åè®¨è®ºç”Ÿæˆå™¨ç½‘ç»œçš„ä¸»è¦åŠŸèƒ½ï¼š


```python
class _netG(nn.Module):
    def __init__(self):
        super(_netG, self).__init__()

        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )

    def forward(self, input):
        output = self.main(input)
        return output
```

åœ¨æˆ‘ä»¬çœ‹åˆ°çš„å¤§å¤šæ•°ä»£ç ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€å †ä¸åŒçš„å±‚ï¼Œç„¶ååœ¨forwardæ–¹æ³•ä¸­å®šä¹‰äº†æµã€‚ åœ¨ç”Ÿæˆå™¨ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨é¡ºåºæ¨¡å‹åœ¨initæ–¹æ³•å†…å®šä¹‰å±‚å’Œæ•°æ®æµã€‚
è¯¥æ¨¡å‹å°†å¤§å°ä¸ºnzçš„å¼ é‡ä½œä¸ºè¾“å…¥ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™è½¬ç½®å·ç§¯ï¼Œä»¥å°†è¾“å…¥æ˜ å°„åˆ°å®ƒéœ€è¦ç”Ÿæˆçš„å›¾åƒå¤§å°ã€‚ forwardå‡½æ•°å°†è¾“å…¥ä¼ é€’ç»™é¡ºåºæ¨¡å—å¹¶è¿”å›è¾“å‡ºã€‚
ç”Ÿæˆå™¨ç½‘ç»œçš„æœ€åä¸€å±‚æ˜¯tanhå±‚ï¼Œå®ƒé™åˆ¶äº†ç½‘ç»œå¯ä»¥ç”Ÿæˆçš„å€¼çš„èŒƒå›´ã€‚




# ç½‘ç»œåˆå§‹åŒ–


æˆ‘ä»¬ä¸æ˜¯ä½¿ç”¨ç›¸åŒçš„éšæœºæƒé‡ï¼Œè€Œæ˜¯ä½¿ç”¨æœ¬æ–‡ä¸­å®šä¹‰çš„æƒé‡åˆå§‹åŒ–æ¨¡å‹ã€‚ ä»¥ä¸‹æ˜¯æƒé‡åˆå§‹åŒ–ä»£ç ï¼š


```python
# custom weights initialization called on netG and netD
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)
```


```python
netG = _netG()
netG.apply(weights_init)
print(netG)
```

    _netG(
      (main): Sequential(
        (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
        (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): ReLU(inplace)
        (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (11): ReLU(inplace)
        (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (13): Tanh()
      )
    )


æˆ‘ä»¬é€šè¿‡å°†å‡½æ•°ä¼ é€’ç»™ç”Ÿæˆå™¨å¯¹è±¡netGæ¥è°ƒç”¨æƒé‡å‡½æ•°ã€‚ æ¯ä¸€å±‚éƒ½ä¼ é€’ç»™å‡½æ•°; å¦‚æœå›¾å±‚æ˜¯å·ç§¯å›¾å±‚ï¼Œæˆ‘ä»¬ä¼šä»¥ä¸åŒçš„æ–¹å¼åˆå§‹åŒ–æƒé‡ï¼Œå¦‚æœå®ƒæ˜¯BatchNormï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¼šç¨å¾®åˆå§‹åŒ–å®ƒã€‚ æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç åœ¨ç½‘ç»œå¯¹è±¡ä¸Šè°ƒç”¨è¯¥å‡½æ•°ï¼š

```python
netG.apply(weights_init)
```

# å®šä¹‰é‰´åˆ«å™¨ç½‘ç»œ

è®©æˆ‘ä»¬å¿«é€ŸæŸ¥çœ‹ä»¥ä¸‹é‰´åˆ«å™¨ç½‘ç»œä»£ç ï¼Œç„¶åè®¨è®ºé‰´åˆ«å™¨ç½‘ç»œçš„ä¸»è¦ç‰¹æ€§ï¼š


```python
class _netD(nn.Module):
    def __init__(self):
        super(_netD, self).__init__()
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        output = self.main(input)
        return output.view(-1, 1).squeeze(1)


netD = _netD()
netD.apply(weights_init)
print(netD)
```

    _netD(
      (main): Sequential(
        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (1): LeakyReLU(negative_slope=0.2, inplace)
        (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): LeakyReLU(negative_slope=0.2, inplace)
        (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (7): LeakyReLU(negative_slope=0.2, inplace)
        (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (10): LeakyReLU(negative_slope=0.2, inplace)
        (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
        (12): Sigmoid()
      )
    )


åœ¨å…ˆå‰çš„ç½‘ç»œä¸­æœ‰ä¸¤ä¸ªé‡è¦çš„äº‹æƒ…ï¼Œå³ä½¿ç”¨æ³„æ¼çš„ReLUä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œä»¥åŠä½¿ç”¨sigmoidä½œä¸ºæœ€åçš„æ¿€æ´»å±‚ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬äº†è§£Leaky ReLUæ˜¯ä»€ä¹ˆã€‚

Leaky ReLUè¯•å›¾è§£å†³å‚æ­»çš„ReLUé—®é¢˜ã€‚å½“è¾“å…¥ä¸ºè´Ÿæ—¶ï¼Œæ³„æ¼çš„ReLUå°†è¾“å‡ºä¸€ä¸ªéå¸¸å°çš„æ•°å­—ï¼Œå¦‚0.001ï¼Œè€Œä¸æ˜¯å‡½æ•°è¿”å›é›¶ã€‚åœ¨è®ºæ–‡ä¸­ï¼Œè¡¨æ˜ä½¿ç”¨æ³„æ¼çš„ReLUå¯ä»¥æé«˜é‰´åˆ«å™¨çš„æ•ˆç‡ã€‚

å¦ä¸€ä¸ªé‡è¦çš„åŒºåˆ«æ˜¯åœ¨é‰´åˆ«å™¨çš„æœ«ç«¯æ²¡æœ‰ä½¿ç”¨å®Œå…¨è¿æ¥çš„å±‚ã€‚é€šå¸¸ä¼šçœ‹åˆ°æœ€åä¸€ä¸ªå®Œå…¨è¿æ¥çš„å±‚è¢«å…¨å±€å¹³å‡æ± æ›¿æ¢ã€‚ä½†æ˜¯ä½¿ç”¨å…¨å±€å¹³å‡æ± ä¼šé™ä½æ”¶æ•›é€Ÿåº¦ï¼ˆæ„å»ºç²¾ç¡®åˆ†ç±»å™¨çš„è¿­ä»£æ¬¡æ•°ï¼‰ã€‚æœ€åçš„å·ç§¯å±‚å˜å¹³å¹¶ä¼ é€’åˆ°Så½¢å±‚ã€‚

é™¤äº†è¿™ä¸¤ä¸ªå·®å¼‚ä¹‹å¤–ï¼Œç½‘ç»œçš„å…¶ä½™éƒ¨åˆ†ä¸æˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­çœ‹åˆ°çš„å…¶ä»–å›¾åƒåˆ†ç±»å™¨ç½‘ç»œç±»ä¼¼ã€‚


# å®šä¹‰æŸå¤±å’Œä¼˜åŒ–å™¨
æˆ‘ä»¬å°†åœ¨ä»¥ä¸‹ä»£ç ä¸­å®šä¹‰äºŒè¿›åˆ¶äº¤å‰ç†µæŸå¤±å’Œä¸¤ä¸ªä¼˜åŒ–å™¨ï¼Œä¸€ä¸ªç”¨äºç”Ÿæˆå™¨ï¼Œå¦ä¸€ä¸ªç”¨äºé‰´åˆ«å™¨ï¼š



```python

criterion = nn.BCELoss()

input = torch.FloatTensor(batch_size, 3, img_size, img_size)
noise = torch.FloatTensor(batch_size, nz, 1, 1)
fixed_noise = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)
label = torch.FloatTensor(batch_size)
real_label = 1
fake_label = 0
```


```python
if torch.cuda.is_available():
    netD.cuda()
    netG.cuda()
    criterion.cuda()
    input, label = input.cuda(), label.cuda()
    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()
```

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œå®ƒä¸æˆ‘ä»¬ä¹‹å‰çš„æ‰€æœ‰ç¤ºä¾‹ä¸­çœ‹åˆ°çš„éå¸¸ç›¸ä¼¼ã€‚ è®©æˆ‘ä»¬æ¢è®¨å¦‚ä½•è®­ç»ƒç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨ã€‚


```python
fixed_noise = Variable(fixed_noise)

# setup optimizer
optimizerD = optim.Adam(netD.parameters(), lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr, betas=(beta1, 0.999))
```

## è®­ç»ƒé‰´åˆ«å™¨

é‰´åˆ«å™¨ç½‘ç»œçš„æŸå¤±å–å†³äºå®ƒåœ¨çœŸå®å›¾åƒä¸Šçš„è¡¨ç°ä»¥åŠå®ƒå¦‚ä½•å¯¹ç”Ÿæˆå™¨ç½‘ç»œç”Ÿæˆçš„å‡å›¾åƒæ‰§è¡Œåˆ¤æ–­çš„ç»“æœã€‚ æŸå¤±å¯ä»¥å®šä¹‰ä¸ºï¼š

$loss = maximize \log(D(x)) + \log(1-D(G(z)))$

å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨çœŸå®å›¾åƒå’Œç”Ÿæˆå™¨ç½‘ç»œç”Ÿæˆçš„ä¼ªå›¾åƒæ¥è®­ç»ƒé‰´åˆ«å™¨ã€‚

## ç”¨çœŸå®å›¾åƒè®­ç»ƒé‰´åˆ«å™¨
è®©æˆ‘ä»¬ä¼ é€’ä¸€äº›çœŸå®çš„å›¾åƒä½œä¸ºåŸºç¡€äº‹å®æ¥è®­ç»ƒé‰´åˆ«å™¨ã€‚
é¦–å…ˆï¼Œæˆ‘ä»¬å°†çœ‹çœ‹æ‰§è¡Œç›¸åŒæ“ä½œçš„ä»£ç ï¼Œç„¶åæ¢ç´¢é‡è¦çš„åŠŸèƒ½ï¼š
```python
output = netD(inputv)
errD_real = criterion(output, labelv)
errD_real.backward()
```
åœ¨å‰é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬è®¡ç®—é‰´åˆ«å™¨å›¾åƒæ‰€éœ€çš„æŸè€—å’Œæ¢¯åº¦ã€‚ inputvå’Œlabelvè¡¨ç¤ºæ¥è‡ªCIFAR10çš„è¾“å…¥å›¾åƒæ•°æ®é›†å’Œæ ‡ç­¾ï¼Œç”¨äºå®é™…å›¾åƒã€‚ å®ƒéå¸¸ç®€å•ï¼Œå› ä¸ºå®ƒä¸æˆ‘ä»¬å¯¹å…¶ä»–å›¾åƒåˆ†ç±»å™¨ç½‘ç»œçš„æ“ä½œç±»ä¼¼ã€‚


## ç”¨å‡å›¾åƒè®­ç»ƒé‰´åˆ«å™¨
ç°åœ¨ä¼ é€’ä¸€äº›éšæœºå›¾åƒæ¥è®­ç»ƒé‰´åˆ«å™¨ã€‚
è®©æˆ‘ä»¬çœ‹çœ‹å®ƒçš„ä»£ç ï¼Œç„¶åæ¢ç´¢é‡è¦çš„åŠŸèƒ½ï¼š

```python
fake = netG(noisev)
output = netD(fake.detach())
errD_fake = criterion(output, labelv)
errD_fake.backward()
optimizerD.step() 
```
æ­¤ä»£ç ä¸­çš„ç¬¬ä¸€è¡Œä¼ é€’å¤§å°ä¸º100çš„å‘é‡ï¼Œç”Ÿæˆå™¨ç½‘ç»œï¼ˆnetGï¼‰ç”Ÿæˆå›¾åƒã€‚ æˆ‘ä»¬å°†å›¾åƒä¼ é€’ç»™é‰´åˆ«å™¨ï¼Œä»¥è¯†åˆ«å›¾åƒæ˜¯çœŸå®çš„è¿˜æ˜¯å‡çš„ã€‚ æˆ‘ä»¬ä¸å¸Œæœ›å‘ç”Ÿå™¨æ¥å—è®­ç»ƒï¼Œå› ä¸ºé‰´åˆ«å™¨æ­£åœ¨æ¥å—è®­ç»ƒã€‚ å› æ­¤ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨å…¶å˜é‡ä¸Šè°ƒç”¨detachæ–¹æ³•ä»å›¾ä¸­åˆ é™¤ä¼ªå›¾åƒã€‚ è®¡ç®—å®Œæ‰€æœ‰æ¢¯åº¦åï¼Œæˆ‘ä»¬è°ƒç”¨ä¼˜åŒ–å™¨æ¥è®­ç»ƒé‰´åˆ«å™¨ã€‚


##  è®­ç»ƒç”Ÿæˆå™¨ç½‘ç»œ
è®©æˆ‘ä»¬çœ‹çœ‹å®ƒçš„ä»£ç ï¼Œç„¶åæ¢ç´¢é‡è¦çš„åŠŸèƒ½ï¼š
```python
netG.zero_grad()
labelv = Variable(label.fill_(real_label)) # fake labels are real for
generator cost
output = netD(fake)
errG = criterion(output, labelv)
errG.backward()
optimizerG.step()
```

å®ƒçœ‹èµ·æ¥ç±»ä¼¼äºæˆ‘ä»¬åœ¨å‡å›¾åƒä¸Šè®­ç»ƒé‰´åˆ«å™¨æ—¶æ‰€åšçš„ï¼Œé™¤äº†ä¸€äº›å…³é”®çš„å·®å¼‚ã€‚ æˆ‘ä»¬ä¼ é€’çš„æ˜¯ç”±ç”Ÿæˆå™¨åˆ›å»ºçš„ç›¸åŒçš„è™šå‡å›¾åƒï¼Œä½†è¿™æ¬¡æˆ‘ä»¬æ²¡æœ‰å°†å®ƒä»ç”Ÿæˆå®ƒçš„å›¾å½¢ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œå› ä¸ºæˆ‘ä»¬å¸Œæœ›å¯¹ç”Ÿæˆå™¨è¿›è¡Œè®­ç»ƒã€‚ æˆ‘ä»¬è®¡ç®—æŸå¤±ï¼ˆerrGï¼‰å¹¶è®¡ç®—æ¢¯åº¦ã€‚ ç„¶åæˆ‘ä»¬è°ƒç”¨ç”Ÿæˆå™¨ä¼˜åŒ–å™¨ï¼Œå› ä¸ºæˆ‘ä»¬åªéœ€è¦è®­ç»ƒç”Ÿæˆå™¨ï¼Œå¹¶ä¸”åœ¨ç”Ÿæˆå™¨ç”Ÿæˆç¨å¾®é€¼çœŸçš„å›¾åƒä¹‹å‰ï¼Œæˆ‘ä»¬é‡å¤æ•´ä¸ªè¿‡ç¨‹å‡ æ¬¡è¿­ä»£ã€‚

# è®­ç»ƒå®Œæ•´çš„ç½‘ç»œ

æˆ‘ä»¬æŸ¥çœ‹äº†GANå¦‚ä½•è®­ç»ƒçš„å„ä¸ªéƒ¨åˆ†ã€‚ è®©æˆ‘ä»¬æ€»ç»“å¦‚ä¸‹ï¼Œçœ‹çœ‹å°†ç”¨äºè®­ç»ƒæˆ‘ä»¬åˆ›å»ºçš„GANç½‘ç»œçš„å®Œæ•´ä»£ç ï¼š

* ä½¿ç”¨çœŸå®å›¾åƒè®­ç»ƒé‰´åˆ«å™¨ç½‘ç»œ
* ä½¿ç”¨å‡å›¾åƒè®­ç»ƒé‰´åˆ«å™¨ç½‘ç»œ
* ä¼˜åŒ–é‰´åˆ«å™¨
* æ ¹æ®é‰´åˆ«å™¨åé¦ˆè®­ç»ƒç”Ÿæˆå™¨
* å•ç‹¬ä¼˜åŒ–ç”Ÿæˆå™¨ç½‘ç»œ

æˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹ä»£ç æ¥è®­ç»ƒç½‘ç»œï¼š


```python

for epoch in range(niter):
    for i, data in enumerate(dataloader, 0):
        ############################
        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
        ###########################
        # train with real
        netD.zero_grad()
        real_cpu, _ = data
        batch_size = real_cpu.size(0)
        if torch.cuda.is_available():
            real_cpu = real_cpu.cuda()
        input.resize_as_(real_cpu).copy_(real_cpu)
        label.resize_(batch_size).fill_(real_label)
        inputv = Variable(input)
        labelv = Variable(label)

        output = netD(inputv)
        errD_real = criterion(output, labelv)
        errD_real.backward()
        D_x = output.data.mean()

        # train with fake
        noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)
        noisev = Variable(noise)
        fake = netG(noisev)
        labelv = Variable(label.fill_(fake_label))
        output = netD(fake.detach())
        errD_fake = criterion(output, labelv)
        errD_fake.backward()
        D_G_z1 = output.data.mean()
        errD = errD_real + errD_fake
        optimizerD.step()

        ############################
        # (2) Update G network: maximize log(D(G(z)))
        ###########################
        netG.zero_grad()
        labelv = Variable(label.fill_(real_label))  # fake labels are real for generator cost
        output = netD(fake)
        errG = criterion(output, labelv)
        errG.backward()
        D_G_z2 = output.data.mean()
        optimizerG.step()

        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'
              % (epoch, niter, i, len(dataloader),
                 errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2))
        if i % 100 == 0:
            vutils.save_image(real_cpu,
                    '%s/real_samples.png' % outf,
                    normalize=True)
            fake = netG(fixed_noise)
            vutils.save_image(fake.data,
                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),
                    normalize=True)
```

    /Users/zhipingxu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number


    [0/25][0/782] Loss_D: 1.3081 Loss_G: 5.4827 D(x): 0.5424 D(G(z)): 0.4085 / 0.0050
    [0/25][1/782] Loss_D: 1.0166 Loss_G: 6.2396 D(x): 0.8049 D(G(z)): 0.4682 / 0.0028
    ......
 
    [24/25][769/782] Loss_D: 0.2830 Loss_G: 3.4405 D(x): 0.9081 D(G(z)): 0.1581 / 0.0452
    [24/25][770/782] Loss_D: 0.4860 Loss_G: 1.7289 D(x): 0.6942 D(G(z)): 0.0578 / 0.2467
    [24/25][771/782] Loss_D: 0.5691 Loss_G: 4.1471 D(x): 0.9662 D(G(z)): 0.3614 / 0.0240
    [24/25][772/782] Loss_D: 0.4110 Loss_G: 2.4502 D(x): 0.7505 D(G(z)): 0.0824 / 0.1196
    [24/25][773/782] Loss_D: 0.3340 Loss_G: 2.2193 D(x): 0.8551 D(G(z)): 0.1326 / 0.1458
    [24/25][774/782] Loss_D: 0.4986 Loss_G: 4.7749 D(x): 0.9445 D(G(z)): 0.3129 / 0.0130
    [24/25][775/782] Loss_D: 0.6695 Loss_G: 1.2901 D(x): 0.5963 D(G(z)): 0.0374 / 0.3284
    [24/25][776/782] Loss_D: 0.7374 Loss_G: 4.3284 D(x): 0.9487 D(G(z)): 0.4307 / 0.0201
    [24/25][777/782] Loss_D: 0.5875 Loss_G: 1.3599 D(x): 0.6283 D(G(z)): 0.0382 / 0.3141
    [24/25][778/782] Loss_D: 0.5213 Loss_G: 5.0111 D(x): 0.9638 D(G(z)): 0.3450 / 0.0093
    [24/25][779/782] Loss_D: 0.3158 Loss_G: 3.3499 D(x): 0.7886 D(G(z)): 0.0363 / 0.0627
    [24/25][780/782] Loss_D: 0.3591 Loss_G: 2.2062 D(x): 0.8324 D(G(z)): 0.1292 / 0.1598
    [24/25][781/782] Loss_D: 0.3469 Loss_G: 4.5260 D(x): 0.9291 D(G(z)): 0.2104 / 0.0127


`vutils.save_image`å°†é‡‡ç”¨å¼ é‡å¹¶å°†å…¶ä¿å­˜ä¸ºå›¾åƒã€‚ å¦‚æœæä¾›äº†ä¸€å°æ‰¹å›¾åƒï¼Œåˆ™ä¼šå°†å®ƒä»¬ä¿å­˜ä¸ºå›¾åƒç½‘æ ¼ã€‚ åœ¨ä»¥ä¸‹éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†äº†è§£ç”Ÿæˆçš„å›¾åƒå’ŒçœŸå®å›¾åƒçš„å¤–è§‚ã€‚


## æ£€æŸ¥ç”Ÿæˆçš„å›¾åƒ
é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬æ¯”è¾ƒç”Ÿæˆçš„å›¾åƒå’ŒçœŸå®çš„å›¾åƒã€‚
çœŸå®çš„å›¾åƒå¦‚ä¸‹ï¼š



```python
mkdir output
```

    mkdir: output: File exists



```python
ls -al output/
```

    total 24112
    drwxr-xr-x@ 28 zhipingxu  staff     896  2 22 14:27 [34m.[m[m/
    drwxr-xr-x@  6 zhipingxu  staff     192  7 26 08:29 [34m..[m[m/
    -rwxr-xr-x@  1 zhipingxu  staff  576692  7 26 08:07 [31mfake_samples_epoch_000.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  523041  7 26 08:08 [31mfake_samples_epoch_001.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  492631  7 26 08:09 [31mfake_samples_epoch_002.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  463971  7 26 08:10 [31mfake_samples_epoch_003.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  457205  7 26 08:11 [31mfake_samples_epoch_004.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  456695  7 26 08:11 [31mfake_samples_epoch_005.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  451312  7 26 08:12 [31mfake_samples_epoch_006.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  449773  7 26 08:13 [31mfake_samples_epoch_007.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  458245  7 26 08:14 [31mfake_samples_epoch_008.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  455169  7 26 08:15 [31mfake_samples_epoch_009.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  445409  7 26 08:15 [31mfake_samples_epoch_010.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  454499  7 26 08:16 [31mfake_samples_epoch_011.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  448112  7 26 08:17 [31mfake_samples_epoch_012.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  456534  7 26 08:18 [31mfake_samples_epoch_013.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  512600  7 26 08:19 [31mfake_samples_epoch_014.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  617002  7 26 08:20 [31mfake_samples_epoch_015.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  519844  7 26 08:21 [31mfake_samples_epoch_016.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  483314  7 26 08:21 [31mfake_samples_epoch_017.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  454078  7 26 08:22 [31mfake_samples_epoch_018.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  449906  7 26 08:23 [31mfake_samples_epoch_019.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  465097  7 26 08:24 [31mfake_samples_epoch_020.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  451727  7 26 08:25 [31mfake_samples_epoch_021.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  465777  7 26 08:25 [31mfake_samples_epoch_022.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  451261  7 26 08:26 [31mfake_samples_epoch_023.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  454580  7 26 08:27 [31mfake_samples_epoch_024.png[m[m*
    -rwxr-xr-x@  1 zhipingxu  staff  385514  7 26 08:27 [31mreal_samples.png[m[m*



```python
Image.open('output/real_samples.png')
```




![png](output_38_0.png)



ç”Ÿæˆçš„å›¾åƒå¦‚ä¸‹ï¼š


```python
Image.open('output/fake_samples_epoch_024.png')
```




![png](output_40_0.png)



æ¯”è¾ƒä¸¤ç»„å›¾åƒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„GANèƒ½å¤Ÿå­¦ä¹ å¦‚ä½•ç”Ÿæˆå›¾åƒã€‚ é™¤äº†åŸ¹è®­ä»¥ç”Ÿæˆæ–°å›¾åƒä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ªé‰´åˆ«å™¨ï¼Œå¯ç”¨äºåˆ†ç±»é—®é¢˜ã€‚ å½“å­˜åœ¨æœ‰é™é‡çš„æ ‡è®°æ•°æ®æ—¶ï¼Œé‰´åˆ«å™¨å­¦ä¹ å…³äºå›¾åƒçš„é‡è¦ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯ç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚ å½“æ ‡è®°æ•°æ®æœ‰é™æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥è®­ç»ƒä¸€ä¸ªGANï¼Œå®ƒå°†ä¸ºæˆ‘ä»¬æä¾›ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œå¯ç”¨äºæå–ç‰¹å¾ - å¹¶ä¸”å¯ä»¥åœ¨å…¶ä¸Šæ„å»ºåˆ†ç±»å™¨æ¨¡å—ã€‚

åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®­ç»ƒæ·±åº¦å­¦ä¹ ç®—æ³•æ¥ç”Ÿæˆæ–‡æœ¬ã€‚

# è¯­è¨€å»ºæ¨¡

æˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•æ•™æˆé€’å½’ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å¦‚ä½•åˆ›å»ºä¸€ç³»åˆ—æ–‡æœ¬ã€‚ç®€å•æ¥è¯´ï¼Œæˆ‘ä»¬ç°åœ¨å°†æ„å»ºçš„RNNæ¨¡å‹èƒ½å¤Ÿåœ¨ç»™å®šæŸäº›ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚è¿™å°±åƒæ‰‹æœºä¸Šçš„Swiftåº”ç”¨ç¨‹åºä¸€æ ·ï¼Œå®ƒä¼šçŒœåˆ°ä½ è¾“å…¥çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚ç”Ÿæˆé¡ºåºæ•°æ®çš„èƒ½åŠ›åœ¨è®¸å¤šä¸åŒé¢†åŸŸéƒ½æœ‰åº”ç”¨ï¼Œä¾‹å¦‚ï¼š

* ç»™å›¾åƒåŠ æ–‡æœ¬æ ‡æ³¨
* è¯­éŸ³è¯†åˆ«
* è¯­è¨€ç¿»è¯‘
* è‡ªåŠ¨ç”µå­é‚®ä»¶å›å¤

æˆ‘ä»¬åœ¨ç¬¬6ç« â€œä½¿ç”¨åºåˆ—æ•°æ®å’Œæ–‡æœ¬è¿›è¡Œæ·±åº¦å­¦ä¹ â€ä¸­äº†è§£åˆ°ï¼ŒRNNå¾ˆéš¾è®­ç»ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç§°ä¸ºé•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰çš„RNNå˜ä½“ã€‚ LSTMç®—æ³•çš„å¼€å‘å§‹äº1997å¹´ï¼Œä½†åœ¨è¿‡å»å‡ å¹´ä¸­å˜å¾—æµè¡Œã€‚ç”±äºå¼ºå¤§çš„ç¡¬ä»¶å’Œè´¨é‡æ•°æ®çš„å¯ç”¨æ€§ï¼Œå®ƒå˜å¾—æµè¡Œï¼Œå¹¶ä¸”è¯¸å¦‚dropout çš„ä¸€äº›è¿›æ­¥ä¹Ÿæœ‰åŠ©äºæ¯”ä»¥å‰æ›´å®¹æ˜“åœ°è®­ç»ƒæ›´å¥½çš„LSTMæ¨¡å‹ã€‚

ä½¿ç”¨LSTMæ¨¡å‹ç”Ÿæˆå­—ç¬¦çº§è¯­è¨€æ¨¡å‹æˆ–å•è¯çº§è¯­è¨€æ¨¡å‹éå¸¸æµè¡Œã€‚åœ¨å­—ç¬¦çº§è¯­è¨€å»ºæ¨¡ä¸­ï¼Œæˆ‘ä»¬ç»™å‡ºä¸€ä¸ªå­—ç¬¦ï¼Œè®­ç»ƒLSTMæ¨¡å‹æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦ï¼Œè€Œåœ¨å­—çº§è¯­è¨€å»ºæ¨¡ä¸­ï¼Œæˆ‘ä»¬ç»™å‡ºä¸€ä¸ªå•è¯ï¼ŒLSTMæ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨PyTorch LSTMæ¨¡å‹æ„å»ºä¸€ä¸ªå•è¯çº§è¯­è¨€æ¨¡å‹ã€‚å°±åƒåŸ¹è®­ä»»ä½•å…¶ä»–æ¨¡å—ä¸€æ ·ï¼Œæˆ‘ä»¬å°†éµå¾ªæ ‡å‡†æ­¥éª¤ï¼š

* å‡†å¤‡æ•°æ®
* ç”Ÿæˆæ‰¹é‡æ•°æ®
* åŸºäºLSTMå®šä¹‰æ¨¡å‹
* è®­ç»ƒæ¨¡å‹
* æµ‹è¯•æ¨¡å‹

æœ¬èŠ‚çš„çµæ„Ÿæ¥è‡ªPyTorchä¸­æä¾›çš„å•è¯è¯­è¨€å»ºæ¨¡ç¤ºä¾‹çš„ç•¥å¾®ç®€åŒ–ç‰ˆæœ¬ï¼Œç½‘å€ä¸ºhttps://github.com/pytorch/examples/tree/master/word_language_model ã€‚


```python
import argparse
import os
import time
import math
import torch
import torch.nn as nn
from torch.autograd import Variable
from torchtext import data as d
from torchtext import datasets
from torchtext.vocab import GloVe
import model
```


```python
is_cuda = torch.cuda.is_available()
is_cuda
```




    True



## å‡†å¤‡æ•°æ®

å¯¹äºæ­¤ç¤ºä¾‹ï¼Œæˆ‘ä»¬ä½¿ç”¨åä¸ºWikiText2çš„æ•°æ®é›†ã€‚ WikiTextè¯­è¨€å»ºæ¨¡æ•°æ®é›†æ˜¯ä»ç»´åŸºç™¾ç§‘ä¸Šç»è¿‡éªŒè¯çš„Goodå’ŒFeaturedæ–‡ç« é›†ä¸­æå–çš„è¶…è¿‡1äº¿ä¸ªä»¤ç‰Œçš„é›†åˆã€‚ ä¸Penn Treebankï¼ˆPTBï¼‰çš„é¢„å¤„ç†ç‰ˆæœ¬ï¼ˆå¦ä¸€ä¸ªå¸¸ç”¨çš„æ•°æ®é›†ï¼‰ç›¸æ¯”ï¼ŒWikiText-2çš„æ•°é‡å¢åŠ äº†ä¸¤å€å¤šã€‚ WikiTextæ•°æ®é›†è¿˜å…·æœ‰æ›´å¤§çš„è¯æ±‡è¡¨ï¼Œå¹¶ä¿ç•™åŸå§‹æ¡ˆä¾‹ï¼Œæ ‡ç‚¹ç¬¦å·å’Œæ•°å­—ã€‚ è¯¥æ•°æ®é›†åŒ…å«å®Œæ•´çš„æ–‡ç« ï¼Œå› æ­¤ï¼Œå®ƒéå¸¸é€‚åˆåˆ©ç”¨é•¿æœŸä¾èµ–æ€§çš„æ¨¡å‹ã€‚

è¯¥æ•°æ®é›†åœ¨ä¸€ç¯‡åä¸ºPointer Sentinel Mixture Modelsï¼ˆhttps://arxiv.org/abs/1609.07843ï¼‰çš„è®ºæ–‡ä¸­ä»‹ç»ã€‚ æœ¬æ–‡è®¨è®ºäº†å¯ç”¨äºè§£å†³ç‰¹å®šé—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼Œå…¶ä¸­å…·æœ‰softmaxå±‚çš„LSTMéš¾ä»¥é¢„æµ‹ç½•è§è¯ï¼Œå°½ç®¡ä¸Šä¸‹æ–‡ä¸æ¸…æ¥šã€‚ ç°åœ¨è®©æˆ‘ä»¬ä¸è¦æ‹…å¿ƒï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå…ˆè¿›çš„æ¦‚å¿µï¼Œè¶…å‡ºäº†æœ¬ä¹¦çš„èŒƒå›´ã€‚

ä»¥ä¸‹å±å¹•æˆªå›¾æ˜¾ç¤ºäº†WikiTextè½¬å‚¨ä¸­çš„æ•°æ®ï¼š
![](https://bennix.github.io/imgs/6_20.png)



åƒå¾€å¸¸ä¸€æ ·ï¼Œé€šè¿‡æä¾›ä¸‹è½½å’Œè¯»å–æ•°æ®é›†çš„æŠ½è±¡ï¼Œtorchtextä½¿å¾—ä½¿ç”¨æ•°æ®é›†å˜å¾—æ›´åŠ å®¹æ˜“ã€‚ è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹ä»£ç ï¼š


```python
TEXT = d.Field(lower=True, batch_first=True,)
```


```python
# make splits for data
train, valid, test = datasets.WikiText2.splits(TEXT,root='data')
```

å‰é¢çš„ä»£ç è´Ÿè´£ä¸‹è½½WikiText2æ•°æ®å¹¶å°†å…¶æ‹†åˆ†ä¸ºtrainï¼Œvalidå’Œtestæ•°æ®é›†ã€‚ è¯­è¨€å»ºæ¨¡çš„å…³é”®åŒºåˆ«åœ¨äºå¦‚ä½•å¤„ç†æ•°æ®ã€‚ æˆ‘ä»¬åœ¨WikiText2ä¸­çš„æ‰€æœ‰æ–‡æœ¬æ•°æ®éƒ½å­˜å‚¨åœ¨ä¸€ä¸ªé•¿å¼ é‡ä¸­ã€‚ è®©æˆ‘ä»¬çœ‹çœ‹ä¸‹é¢çš„ä»£ç å’Œç»“æœï¼Œä»¥äº†è§£å¦‚ä½•æ›´å¥½åœ°å¤„ç†æ•°æ®ï¼š


```python
batch_size=20
bptt_len=30
clip = 0.25
lr = 20
log_interval = 200
```


```python
(len(valid[0].text)//batch_size)*batch_size
```




    217640




```python
len(train[0].text)
```




    2088628



ä»å‰é¢çš„ç»“æœæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬åªæœ‰ä¸€ä¸ªç¤ºä¾‹å­—æ®µï¼Œå®ƒåŒ…å«æ‰€æœ‰æ–‡æœ¬ã€‚ æˆ‘ä»¬è¿˜å¿«é€ŸæŸ¥çœ‹æ–‡æœ¬çš„è¡¨ç¤ºæ–¹å¼ï¼š


```python
print(train[0].text[:100])
```

    ['<eos>', '=', 'valkyria', 'chronicles', 'iii', '=', '<eos>', '<eos>', 'senjÅ', 'no', 'valkyria', '3', ':', '<unk>', 'chronicles', '(', 'japanese', ':', 'æˆ¦å ´ã®ãƒ´ã‚¡ãƒ«ã‚­ãƒ¥ãƒªã‚¢3', ',', 'lit', '.', 'valkyria', 'of', 'the', 'battlefield', '3', ')', ',', 'commonly', 'referred', 'to', 'as', 'valkyria', 'chronicles', 'iii', 'outside', 'japan', ',', 'is', 'a', 'tactical', 'role', '@-@', 'playing', 'video', 'game', 'developed', 'by', 'sega', 'and', 'media.vision', 'for', 'the', 'playstation', 'portable', '.', 'released', 'in', 'january', '2011', 'in', 'japan', ',', 'it', 'is', 'the', 'third', 'game', 'in', 'the', 'valkyria', 'series', '.', '<unk>', 'the', 'same', 'fusion', 'of', 'tactical', 'and', 'real', '@-@', 'time', 'gameplay', 'as', 'its', 'predecessors', ',', 'the', 'story', 'runs', 'parallel', 'to', 'the', 'first', 'game', 'and', 'follows', 'the']



```python
train[0].text = train[0].text[:(len(train[0].text)//batch_size)*batch_size]
valid[0].text = valid[0].text[:(len(valid[0].text)//batch_size)*batch_size]
test[0].text = test[0].text[:(len(valid[0].text)//batch_size)*batch_size]

```


```python
len(valid[0].text)
```




    217640




```python
# print information about the data
print('train.fields', train.fields)
print('len(train)', len(train))
print('vars(train[0])', vars(train[0])['text'][0:10])
```

    train.fields {'text': <torchtext.data.field.Field object at 0x15e91dfd0>}
    len(train) 1
    vars(train[0]) ['<eos>', '=', 'valkyria', 'chronicles', 'iii', '=', '<eos>', '<eos>', 'senjÅ', 'no']



```python
TEXT.build_vocab(train)
```


```python
print('len(TEXT.vocab)', len(TEXT.vocab))
```

    len(TEXT.vocab) 28913


ç°åœ¨ï¼Œå¿«é€ŸæŸ¥çœ‹æ˜¾ç¤ºåˆå§‹æ–‡æœ¬çš„å›¾åƒä»¥åŠå¦‚ä½•å¯¹å…¶è¿›è¡Œæ ‡è®°åŒ–ã€‚ ç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªé•¿åºåˆ—ï¼Œé•¿åº¦ä¸º2088628ï¼Œä»£è¡¨WikiText2ã€‚ ä¸‹ä¸€ä¸ªé‡è¦çš„æ˜¯æˆ‘ä»¬å¦‚ä½•æ‰¹é‡å¤„ç†æ•°æ®ã€‚


## ç”Ÿæˆæ‰¹æ¬¡
è®©æˆ‘ä»¬çœ‹çœ‹ä»£ç å¹¶ç†è§£é¡ºåºæ•°æ®æ‰¹å¤„ç†ä¸­æ¶‰åŠçš„ä¸¤ä¸ªå…³é”®äº‹é¡¹ï¼š


```python
train_iter, valid_iter, test_iter = d.BPTTIterator.splits((train, valid, test), 
                                                             batch_size=20, 
                                                             bptt_len=35, device=0)

```

é€šè¿‡è¿™ç§æ–¹æ³•æœ‰ä¸¤ä¸ªé‡è¦çš„äº‹æƒ…ã€‚ ä¸€ä¸ªæ˜¯batch_sizeï¼Œå¦ä¸€ä¸ªæ˜¯bptt_lenï¼Œç§°ä¸ºåå‘ä¼ æ’­ã€‚ å®ƒç®€è¦ä»‹ç»äº†å¦‚ä½•é€šè¿‡æ¯ä¸ªé˜¶æ®µè½¬æ¢æ•°æ®ã€‚


## æ‰¹æ¬¡

å°†æ•´ä¸ªæ•°æ®ä½œä¸ºåºåˆ—å¤„ç†æ˜¯éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§çš„å¹¶ä¸”è®¡ç®—æ•ˆç‡ä¸é«˜ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å°†åºåˆ—æ•°æ®åˆ†æˆå¤šä¸ªæ‰¹æ¬¡ï¼Œå¹¶å°†æ¯ä¸ªæ•°æ®è§†ä¸ºä¸€ä¸ªå•ç‹¬çš„åºåˆ—ã€‚ è™½ç„¶å®ƒå¯èƒ½å¬èµ·æ¥å¹¶ä¸ç®€å•ï¼Œä½†å®ƒå¯ä»¥æ›´å¥½åœ°å·¥ä½œï¼Œå› ä¸ºæ¨¡å‹å¯ä»¥ä»æ‰¹é‡æ•°æ®ä¸­æ›´å¿«åœ°å­¦ä¹ ã€‚ è®©æˆ‘ä»¬ä»¥è‹±è¯­å­—æ¯è¡¨æ’åºä¸ºä¾‹ï¼Œæˆ‘ä»¬å°†å…¶åˆ†æˆå‡ ä¸ªæ‰¹æ¬¡ã€‚

é¡ºåºï¼šaï¼Œbï¼Œcï¼Œdï¼Œeï¼Œfï¼Œgï¼Œhï¼Œiï¼Œjï¼Œkï¼Œlï¼Œmï¼Œnï¼Œoï¼Œpï¼Œqï¼Œrï¼Œsï¼Œtï¼Œuï¼Œvï¼Œwï¼Œxï¼Œ yï¼Œzã€‚

å½“æˆ‘ä»¬å°†å‰é¢çš„å­—æ¯åºåˆ—è½¬æ¢ä¸ºå››ä¸ªæ‰¹æ¬¡æ—¶ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š
```
a g m s y
b h n t z
c i o uâ€ƒ
d j p v
e k q w
f l r x
```
åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æœ€ç»ˆä¼šä¿®å‰ªæœ€åä¸€ä¸ªå½¢æˆå°æ‰¹é‡çš„é¢å¤–å•è¯æˆ–æ ‡è®°ï¼Œå› ä¸ºå®ƒå¯¹æ–‡æœ¬å»ºæ¨¡æ²¡æœ‰å¤ªå¤§å½±å“ã€‚

å¯¹äºç¤ºä¾‹WikiText2ï¼Œå½“æˆ‘ä»¬å°†æ•°æ®æ‹†åˆ†ä¸º20ä¸ªæ‰¹æ¬¡æ—¶ï¼Œæˆ‘ä»¬å°†è·å¾—æ¯ä¸ªæ‰¹å¤„ç†å…ƒç´ 104431ã€‚


## éšç€æ—¶é—´çš„æ¨ç§»åå‘ä¼ æ’­
æˆ‘ä»¬çœ‹åˆ°çš„é€šè¿‡è¿­ä»£å™¨çš„å¦ä¸€ä¸ªé‡è¦å˜é‡æ˜¯åå‘ä¼ æ’­ï¼ˆBPTTï¼‰ã€‚ å®ƒå®é™…æ„å‘³ç€ä»€ä¹ˆï¼Œæ¨¡å‹éœ€è¦è®°ä½çš„åºåˆ—é•¿åº¦ã€‚ æ•°å­—è¶Šå¤§è¶Šå¥½ï¼Œä½†æ¨¡å‹çš„å¤æ‚æ€§å’Œæ¨¡å‹æ‰€éœ€çš„GPUå†…å­˜ä¹Ÿä¼šå¢åŠ ã€‚

ä¸ºäº†æ›´å¥½åœ°ç†è§£å®ƒï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å°†ä»¥å‰çš„æ‰¹é‡å­—æ¯æ•°æ®æ‹†åˆ†ä¸ºé•¿åº¦ä¸º2çš„åºåˆ—ï¼š
```
a g m s
b h n t
```
å‰é¢çš„ä¾‹å­å°†ä½œä¸ºè¾“å…¥ä¼ é€’ç»™æ¨¡å‹ï¼Œè¾“å‡ºå°†æ¥è‡ª
åºåˆ—ä½†åŒ…å«ä¸‹ä¸€ä¸ªå€¼ï¼š

```
b h n t
c I o u
```

å¯¹äºç¤ºä¾‹WikiText2ï¼Œå½“æˆ‘ä»¬æ‹†åˆ†æ‰¹é‡æ•°æ®æ—¶ï¼Œæˆ‘ä»¬è·å¾—æ¯ä¸ªæ‰¹æ¬¡å¤§å°ä¸º30,20çš„æ•°æ®ï¼Œå…¶ä¸­30æ˜¯åºåˆ—é•¿åº¦ã€‚

## åŸºäºLSTMå®šä¹‰æ¨¡å‹
æˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªç±»ä¼¼äºæˆ‘ä»¬åœ¨ç¬¬6ç« â€œä½¿ç”¨åºåˆ—æ•°æ®å’Œæ–‡æœ¬è¿›è¡Œæ·±åº¦å­¦ä¹ â€ä¸­çœ‹åˆ°çš„ç½‘ç»œçš„æ¨¡å‹ï¼Œä½†å®ƒæœ‰ä¸€äº›å…³é”®çš„åŒºåˆ«ã€‚ ç½‘ç»œçš„é«˜çº§æ¶æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![](https://bennix.github.io/imgs/6_21.png)

åƒå¾€å¸¸ä¸€æ ·ï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹ä»£ç ï¼Œç„¶åä»‹ç»å®ƒçš„å…³é”®éƒ¨åˆ†ï¼š


```python
class RNNModel(nn.Module):
    def __init__(self,ntoken,ninp,nhid,nlayers,dropout=0.5,tie_weights=False):
        super().__init__()
        self.drop = nn.Dropout()
        self.encoder = nn.Embedding(ntoken,ninp)
        self.rnn = nn.LSTM(ninp,nhid,nlayers,dropout=dropout)
        self.decoder = nn.Linear(nhid,ntoken)
        if tie_weights:
            self.decoder.weight = self.encoder.weight
        
        self.init_weights()
        self.nhid = nhid
        self.nlayers = nlayers
        
    def init_weights(self):
        initrange = 0.1
        self.encoder.weight.data.uniform_(-initrange,initrange)
        self.decoder.bias.data.fill_(0)
        self.decoder.weight.data.uniform_(-initrange,initrange)
        
    def forward(self,input,hidden): 
        
        emb = self.drop(self.encoder(input))
        output,hidden = self.rnn(emb,hidden)
        output = self.drop(output)
        s = output.size()
        decoded = self.decoder(output.view(s[0]*s[1],s[2]))
        return decoded.view(s[0],s[1],decoded.size(1)),hidden
    
    def init_hidden(self,bsz):
        weight = next(self.parameters()).data
        return(Variable(weight.new(self.nlayers,bsz,self.nhid).zero_()),Variable(weight.new(self.nlayers,bsz,self.nhid).zero_()))
    
```

åœ¨`__init__`æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºæ‰€æœ‰å±‚ï¼Œä¾‹å¦‚åµŒå…¥ï¼Œdropoutï¼ŒRNNå’Œè§£ç å™¨ã€‚åœ¨æ—©æœŸçš„è¯­è¨€æ¨¡å‹ä¸­ï¼ŒåµŒå…¥é€šå¸¸ä¸åœ¨æœ€åä¸€å±‚ä¸­ä½¿ç”¨ã€‚åµŒå…¥çš„ä½¿ç”¨ï¼Œä»¥åŠåˆå§‹åµŒå…¥ä¸æœ€ç»ˆè¾“å‡ºå±‚çš„åµŒå…¥ç›¸ç»“åˆï¼Œæé«˜äº†è¯­è¨€æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚è¿™ä¸ªæ¦‚å¿µåœ¨2016å¹´ç”±Press and Wolfä½¿ç”¨è¾“å‡ºåµŒå…¥æ”¹è¿›è¯­è¨€æ¨¡å‹ï¼ˆhttps://arxiv.org/abs/1608.05859 ï¼‰ï¼Œä»¥åŠç»‘å®šå•è¯å‘é‡å’Œå•è¯åˆ†ç±»å™¨ï¼šè¯­è¨€å»ºæ¨¡çš„æŸå¤±æ¡†æ¶ï¼ˆç”±Inanå’Œä»–çš„å…±åŒä½œè€…äº2016å¹´ç¼–å†™çš„https://arxiv.org/abs/i6ii.oi462 ã€‚ä¸€æ—¦æˆ‘ä»¬å°†ç¼–ç å™¨å’Œè§£ç å™¨çš„æƒé‡è”ç³»åœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬å°±ä¼šè°ƒç”¨`init_weights`æ–¹æ³•æ¥åˆå§‹åŒ–å›¾å±‚çš„æƒé‡ã€‚
å‘å‰åŠŸèƒ½å°†æ‰€æœ‰å±‚ç¼åˆåœ¨ä¸€èµ·ã€‚æœ€åçš„çº¿æ€§å›¾å±‚å°†LSTMå›¾å±‚çš„æ‰€æœ‰è¾“å‡ºæ¿€æ´»æ˜ å°„åˆ°å…·æœ‰è¯æ±‡é‡å¤§å°çš„åµŒå…¥ã€‚æ­£å‘å‡½æ•°è¾“å…¥çš„æµç¨‹é€šè¿‡åµŒå…¥å±‚ä¼ é€’ï¼Œç„¶åä¼ é€’ç»™RNNï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒLSTMï¼‰ï¼Œç„¶åä¼ é€’ç»™è§£ç å™¨ï¼Œå¦ä¸€ä¸ªçº¿æ€§å±‚ã€‚

## å®šä¹‰è®­ç»ƒå’Œè¯„ä¼°å‡½æ•°

æ¨¡å‹çš„è®­ç»ƒä¸æˆ‘ä»¬åœ¨æœ¬ä¹¦å‰é¢çš„æ‰€æœ‰ä¾‹å­ä¸­çœ‹åˆ°çš„éå¸¸ç›¸ä¼¼ã€‚ æˆ‘ä»¬éœ€è¦åšå‡ºä¸€äº›é‡è¦çš„æ”¹å˜ï¼Œä»¥ä¾¿è®­ç»ƒæœ‰ç´ çš„æ¨¡å‹æ›´å¥½åœ°è¿ä½œã€‚ æˆ‘ä»¬æ¥çœ‹çœ‹ä»£ç åŠå…¶å…³é”®éƒ¨åˆ†ï¼š


```python
criterion = nn.CrossEntropyLoss()
```


```python
len(valid_iter.dataset[0].text)

```




    217640




```python
def trainf():
    # Turn on training mode which enables dropout.
    lstm.train()
    total_loss = 0
    start_time = time.time()
    hidden = lstm.init_hidden(batch_size)
    for  i,batch in enumerate(train_iter):
        data, targets = batch.text,batch.target.view(-1)
        # Starting each batch, we detach the hidden state from how it was previously produced.
        # If we didn't, the model would try backpropagating all the way to start of the dataset.
        hidden = repackage_hidden(hidden)
        lstm.zero_grad()
        output, hidden = lstm(data, hidden)
        loss = criterion(output.view(-1, ntokens), targets)
        loss.backward()

        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.
        torch.nn.utils.clip_grad_norm(lstm.parameters(), clip)
        for p in lstm.parameters():
            p.data.add_(-lr, p.grad.data)

        total_loss += loss.data

        if i % log_interval == 0 and i > 0:
            cur_loss = total_loss[0] / log_interval
            elapsed = time.time() - start_time
            (print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | loss {:5.2f} | ppl {:8.2f}'.format(epoch, i, len(train_iter), lr,elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss))))
            total_loss = 0
            start_time = time.time()
```

ç”±äºæˆ‘ä»¬åœ¨æ¨¡å‹ä¸­ä½¿ç”¨äº†dropoutï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦åœ¨è®­ç»ƒæœŸé—´ä»¥åŠéªŒè¯/æµ‹è¯•æ•°æ®é›†ä¸­ä½¿ç”¨å®ƒã€‚ åœ¨æ¨¡å‹ä¸Šè°ƒç”¨train()å°†ç¡®ä¿åœ¨è®­ç»ƒæœŸé—´ä¸¢å¤±æ˜¯æ´»åŠ¨çš„ï¼Œå¹¶ä¸”åœ¨æ¨¡å‹ä¸Šè°ƒç”¨eval()å°†ç¡®ä¿ä»¥ä¸åŒæ–¹å¼ä½¿ç”¨dropoutï¼š

```python
lstm.train()
```

å¯¹äºLSTMæ¨¡å‹ä»¥åŠè¾“å…¥ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¼ é€’éšè—å˜é‡ã€‚ `init_hidden`å‡½æ•°å°†æ‰¹é‡å¤§å°ä½œä¸ºè¾“å…¥ï¼Œç„¶åè¿”å›ä¸€ä¸ªéšè—å˜é‡ï¼Œè¯¥å˜é‡å¯ä»¥ä¸è¾“å…¥ä¸€èµ·ä½¿ç”¨ã€‚ æˆ‘ä»¬å¯ä»¥è¿­ä»£è®­ç»ƒæ•°æ®å¹¶å°†è¾“å…¥æ•°æ®ä¼ é€’ç»™æ¨¡å‹ã€‚ ç”±äºæˆ‘ä»¬æ­£åœ¨å¤„ç†åºåˆ—æ•°æ®ï¼Œå› æ­¤æ¯æ¬¡è¿­ä»£çš„æ–°éšè—çŠ¶æ€ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰å¼€å§‹éƒ½æ²¡æœ‰æ„ä¹‰ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å°†é€šè¿‡è°ƒç”¨`detach`æ–¹æ³•å°†å…¶ä»å›¾ä¸­åˆ é™¤åä½¿ç”¨ä¸Šä¸€æ¬¡è¿­ä»£ä¸­çš„éšè—çŠ¶æ€ã€‚ å¦‚æœæˆ‘ä»¬ä¸è°ƒç”¨åˆ†ç¦»æ–¹æ³•ï¼Œé‚£ä¹ˆæˆ‘ä»¬æœ€ç»ˆä¼šè®¡ç®—å¾ˆé•¿åºåˆ—çš„æ¢¯åº¦ï¼Œç›´åˆ°æˆ‘ä»¬è€—å°½GPUå†…å­˜ã€‚


ç„¶åï¼Œæˆ‘ä»¬å°†è¾“å…¥ä¼ é€’ç»™LSTMæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨`CrossEntropyLoss`è®¡ç®—æŸå¤±ã€‚ ä½¿ç”¨ä»¥å‰çš„éšè—çŠ¶æ€å€¼åœ¨ä»¥ä¸‹`repackage_hidden`å‡½æ•°ä¸­å®ç°ï¼š


```python
def repackage_hidden(h):
    """Wraps hidden states in new Variables, to detach them from their history."""
    if type(h) == Variable:
        return Variable(h.data)
    else:
        return tuple(repackage_hidden(v) for v in h)
```

RNNåŠå…¶å˜ä½“ï¼Œä¾‹å¦‚LSTMå’Œé—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰ï¼Œé­å—ç§°ä¸ºæ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ã€‚ é¿å…æ­¤é—®é¢˜çš„ä¸€ä¸ªç®€å•æŠ€å·§æ˜¯å‰ªåˆ‡æ¸å˜ï¼Œè¿™åœ¨ä»¥ä¸‹ä»£ç ä¸­å®Œæˆï¼š

``` pyhton
torch.nn.utils.clip_grad_norm(lstm.parameters(), clip)
```

æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç æ‰‹åŠ¨è°ƒæ•´å‚æ•°å€¼ã€‚ æ‰‹åŠ¨å®ç°ä¼˜åŒ–å™¨æ¯”ä½¿ç”¨é¢„æ„å»ºçš„ä¼˜åŒ–å™¨æä¾›æ›´å¤§çš„çµæ´»æ€§ï¼š

```python
for p in lstm.parameters():
    p.data.add_(-lr, p.grad.data)
```
æˆ‘ä»¬è¿­ä»£æ‰€æœ‰å‚æ•°å¹¶å°†æ¢¯åº¦å€¼ç›¸åŠ ï¼Œå†ä¹˜ä»¥å­¦ä¹ ç‡ã€‚ ä¸€æ—¦æˆ‘ä»¬æ›´æ–°äº†æ‰€æœ‰å‚æ•°ï¼Œæˆ‘ä»¬å°±ä¼šè®°å½•æ‰€æœ‰ç»Ÿè®¡æ•°æ®ï¼Œä¾‹å¦‚æ—¶é—´ï¼ŒæŸå¤±å’Œå›°æƒ‘ã€‚

æˆ‘ä»¬ä¸ºéªŒè¯ç¼–å†™äº†ä¸€ä¸ªç±»ä¼¼çš„å‡½æ•°ï¼Œæˆ‘ä»¬åœ¨æ¨¡å‹ä¸Šè°ƒç”¨evalæ–¹æ³•ã€‚ ä½¿ç”¨ä»¥ä¸‹ä»£ç å®šä¹‰evaluateå‡½æ•°ï¼š


```python

def evaluate(data_source):
    # Turn on evaluation mode which disables dropout.
    lstm.eval()
    total_loss = 0   
    hidden = lstm.init_hidden(batch_size)
    for batch in data_source:        
        data, targets = batch.text,batch.target.view(-1)
        output, hidden = lstm(data, hidden)
        output_flat = output.view(-1, ntokens)
        total_loss += len(data) * criterion(output_flat, targets).data
        hidden = repackage_hidden(hidden)
    return total_loss[0]/(len(data_source.dataset[0].text)//batch_size) 

```

å¤§å¤šæ•°è®­ç»ƒé€»è¾‘å’Œè¯„ä¼°é€»è¾‘æ˜¯ç›¸ä¼¼çš„ï¼Œé™¤äº†è°ƒç”¨evalè€Œä¸æ›´æ–°æ¨¡å‹çš„å‚æ•°ã€‚

## è®­ç»ƒæ¨¡å‹
æˆ‘ä»¬ä¸ºå¤šä¸ªepochè®­ç»ƒæ¨¡å‹å¹¶ä½¿ç”¨ä»¥ä¸‹ä»£ç å¯¹å…¶è¿›è¡ŒéªŒè¯ï¼š



```python
emsize = 200
nhid=200
nlayers=2
dropout = 0.2

ntokens = len(TEXT.vocab)
lstm = RNNModel(ntokens, emsize, nhid,nlayers, dropout, 'store_true')
if is_cuda:
    lstm = lstm.cuda()
    
# Loop over epochs.
best_val_loss = None
epochs = 40
for epoch in range(1, epochs+1):
    epoch_start_time = time.time()
    trainf()
    val_loss = evaluate(valid_iter)
    print('-' * 89)
    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '
    'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),
    val_loss, math.exp(val_loss)))
    print('-' * 89)
    if not best_val_loss or val_loss < best_val_loss:
        best_val_loss = val_loss
    else:
        # Anneal the learning rate if no improvement has been seen in the validation dataset.
        lr /= 4.0

```

ä¹‹å‰çš„ä»£ç æ­£åœ¨è®­ç»ƒæ¨¡å‹40ä¸ªepochï¼Œæˆ‘ä»¬ä»20çš„é«˜å­¦ä¹ é€Ÿç‡å¼€å§‹ï¼Œå¹¶åœ¨éªŒè¯æŸå¤±é¥±å’Œæ—¶è¿›ä¸€æ­¥å‡å°‘å®ƒã€‚ è¿è¡Œæ¨¡å‹40ä¸ªæ—¶æœŸç»™å‡ºäº†å¤§çº¦108.45çš„pplåˆ†æ•°ã€‚

åœ¨è¿‡å»çš„å‡ ä¸ªæœˆé‡Œï¼Œç ”ç©¶äººå‘˜å¼€å§‹æ¢ç´¢ä»¥å‰çš„æ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªç”¨äºåˆ›å»ºé¢„è®­ç»ƒåµŒå…¥çš„è¯­è¨€æ¨¡å‹ã€‚ å¦‚æœæ‚¨å¯¹æ­¤æ–¹æ³•æ›´æ„Ÿå…´è¶£ï¼Œæˆ‘å¼ºçƒˆå»ºè®®æ‚¨é˜…è¯»Jeremy Howardå’ŒSebastian Ruderæ’°å†™çš„æ–‡æœ¬åˆ†ç±»å¾®è°ƒè¯­è¨€æ¨¡å‹ï¼ˆhttps://arxiv.org/abs/i80i.06i46 ï¼‰ã€‚ è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨è¯­è¨€å»ºæ¨¡æŠ€æœ¯æ¥å‡†å¤‡ç‰¹å®šäºåŸŸçš„å•è¯åµŒå…¥ï¼Œä»¥åå¯ä»¥å°†å…¶ç”¨äºä¸åŒçš„NLPä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬åˆ†ç±»é—®é¢˜ã€‚

## å°ç»“

åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å¦‚ä½•è®­ç»ƒæ·±åº¦å­¦ä¹ ç®—æ³•ï¼Œè¿™äº›ç®—æ³•å¯ä»¥ä½¿ç”¨ç”Ÿæˆç½‘ç»œç”Ÿæˆè‰ºæœ¯é£æ ¼è½¬ç§»ï¼Œä½¿ç”¨GANå’ŒDCGANç”Ÿæˆæ–°å›¾åƒï¼Œä»¥åŠä½¿ç”¨LSTMç½‘ç»œç”Ÿæˆæ–‡æœ¬ã€‚
åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€äº›ç°ä»£æ¶æ„ï¼Œå¦‚ResNetå’ŒInceptionï¼Œç”¨äºæ„å»ºæ›´å¥½çš„è®¡ç®—æœºè§†è§‰æ¨¡å‹å’Œæ¨¡å‹ï¼Œå¦‚åºåˆ—åˆ°åºåˆ—ï¼Œå¯ç”¨äºæ„å»ºè¯­è¨€ç¿»è¯‘å’Œå›¾åƒå­—å¹•ã€‚
