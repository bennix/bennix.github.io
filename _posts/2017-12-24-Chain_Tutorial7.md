---
ilayout: post
title: Chainer å…¥é—¨æ•™ç¨‹ï¼ˆ7ï¼‰æ•°æ®é›†æ¨¡å—ä»‹ç»
date: 2017-12-24
categories: blog
tags: [Chainer,å…¥é—¨æ•™ç¨‹ï¼ˆ7), æ•°æ®é›†æ¨¡å—ä»‹ç»]
descrption: Chainer å…¥é—¨æ•™ç¨‹ï¼ˆ7ï¼‰æ•°æ®é›†æ¨¡å—ä»‹ç»
---

# æ•°æ®é›†æ¨¡å—ä»‹ç»


```python
import numpy as np
import chainer
from chainer import cuda, Function, gradient_check, report, training, utils, Variable
from chainer import datasets, iterators, optimizers, serializers
from chainer import Link, Chain, ChainList
import chainer.functions as F
import chainer.links as L
from chainer.training import extensions
import chainer.dataset
import chainer.datasets
```

## å†…å»ºçš„æ•°æ®æ¨¡å—

ä¸€äº›æ•°æ®é›†æ ¼å¼å·²ç»åœ¨chainer.datasetsä¸­å®ç°ï¼Œä¾‹å¦‚TupleDataset


```python
from chainer.datasets import TupleDataset

x = np.arange(10)
t = x * x

data = TupleDataset(x, t)

print('data type: {}, len: {}'.format(type(data), len(data)))
```

    data type: <class 'chainer.datasets.tuple_dataset.TupleDataset'>, len: 10


ç¬¬`i`ä¸ªæ•°æ®å¯ä»¥é€šè¿‡`data[i]`è®¿é—®ï¼Œæ˜¯ä¸€ä¸ªå…ƒç»„($x_i$, $t_i$, ...)


```python
# get forth data -> x=3, t=9
data[3]
```




    (3, 9)



### åˆ‡ç‰‡è®¿é—®

å½“é€šè¿‡åˆ‡ç‰‡ç´¢å¼•è®¿é—®TupleDatasetæ—¶ï¼Œä¾‹å¦‚`data[i:j]`, è¿”å›ä¸€ä¸ªå…ƒç»„åˆ—è¡¨ $[(x_i, t_i), ..., (x_{j-1}, t_{j-1})]$



```python
# Get 1st, 2nd, 3rd data at the same time.
examples = data[0:4]

print(examples)
print('examples type: {}, len: {}'
      .format(type(examples), len(examples)))
```

    [(0, 0), (1, 1), (2, 4), (3, 9)]
    examples type: <class 'list'>, len: 4


è¦å°†ç¤ºä¾‹è½¬æ¢ä¸ºå°æ‰¹é‡æ ¼å¼ï¼Œå¯ä»¥åœ¨chainer.datasetä¸­ä½¿ç”¨concat_exampleså‡½æ•°ã€‚è¿”å›çš„æ•°å€¼æ ¼å¼æ˜¯ 
`([x_array], [t array], ...)`



```python
from chainer.dataset import concat_examples

data_minibatch = concat_examples(examples)

#print(data_minibatch)
#print('data_minibatch type: {}, len: {}'
#      .format(type(data_minibatch), len(data_minibatch)))

x_minibatch, t_minibatch = data_minibatch
# Now it is array format, which has shape
print('x_minibatch = {}, type: {}, shape: {}'.format(x_minibatch, type(x_minibatch), x_minibatch.shape))
print('t_minibatch = {}, type: {}, shape: {}'.format(t_minibatch, type(t_minibatch), t_minibatch.shape))
```

    x_minibatch = [0 1 2 3], type: <class 'numpy.ndarray'>, shape: (4,)
    t_minibatch = [0 1 4 9], type: <class 'numpy.ndarray'>, shape: (4,)


## DictDataset


```python
from chainer.datasets import DictDataset

x = np.arange(10)
t = x * x

# To construct `DictDataset`, you can specify each key-value pair by passing "key=value" in kwargs.
data = DictDataset(x=x, t=t)

print('data type: {}, len: {}'.format(type(data), len(data)))
```

    data type: <class 'chainer.datasets.dict_dataset.DictDataset'>, len: 10



```python
# Get 3rd data at the same time.
example = data[2]
          
print(example)
print('examples type: {}, len: {}'
      .format(type(example), len(example)))

# You can access each value via key
print('x: {}, t: {}'.format(example['x'], example['t']))
```

    {'x': 2, 't': 4}
    examples type: <class 'dict'>, len: 2
    x: 2, t: 4


## ImageDataset

è¿™æ˜¯å›¾åƒæ•°æ®é›†çš„å®ç”¨å·¥å…·ç±»ã€‚å¦‚æœæ•°æ®é›†çš„æ•°é‡å˜å¾—éå¸¸å¤§ï¼ˆä¾‹å¦‚ImageNetæ•°æ®é›†ï¼‰ï¼Œåˆ™ä¸åƒCIFAR-10æˆ–CIFAR-100é‚£æ ·å°†æ‰€æœ‰å›¾åƒåŠ è½½åˆ°å†…å­˜ä¸­ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯ä»¥ä½¿ç”¨ImageDatasetç±»åœ¨æ¯æ¬¡åˆ›å»ºå°æ‰¹é‡æ—¶ä»å¤–å­˜å‚¨å™¨ï¼ˆä¾‹å¦‚ç¡¬ç›˜ï¼‰ä¸­æ‰“å¼€å›¾åƒã€‚

>ImageDataset å°†åªä¸‹è½½å›¾åƒï¼Œå¦‚æœæ‚¨éœ€è¦å¦ä¸€ä¸ªæ ‡ç­¾ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æ­£åœ¨å¤„ç†å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼‰ï¼Œè¯·ä½¿ç”¨LabeledImageDatasetã€‚

æ‚¨éœ€è¦åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼Œä¾‹å¦‚åå«`images.dat`å…¶ä¸­åŒ…å«è¦ä½¿ç”¨ImageDatasetçš„å›¾åƒè·¯å¾„åˆ—è¡¨ã€‚æœ‰å…³è·¯å¾„æ–‡æœ¬æ–‡ä»¶çš„å¤–è§‚ï¼Œè¯·å‚é˜…å¦‚ä¸‹

```
cute-animal-degu-octodon-71487.jpeg
guinea-pig-pet-nager-rodent-47365.jpeg
kittens-cat-cat-puppy-rush-45170.jpeg
kitty-cat-kitten-pet-45201.jpeg
pexels-photo-96938.jpeg
pexels-photo-126407.jpeg
pexels-photo-206931.jpeg
pexels-photo-208845.jpeg
pexels-photo-209079.jpeg
rat-pets-eat-51340.jpeg
```


```python
import os

from chainer.datasets import ImageDataset

# print('Current direcotory: ', os.path.abspath(os.curdir))

filepath = './data/images.dat'
image_dataset = ImageDataset(filepath, root='./data/images')

print('image_dataset type: {}, len: {}'.format(type(image_dataset), len(image_dataset)))
```

    image_dataset type: <class 'chainer.datasets.image_dataset.ImageDataset'>, len: 10


æˆ‘ä»¬å·²ç»åˆ›å»ºäº†ä¸Šé¢çš„`image_dataset`ï¼Œä½†æ˜¯å›¾åƒè¿˜æ²¡æœ‰æ‰©å±•åˆ°å†…å­˜ä¸­ã€‚
æ¯æ¬¡é€šè¿‡ç´¢å¼•è®¿é—®æ—¶ï¼Œå›¾åƒæ•°æ®éƒ½ä¼šä»å­˜å‚¨å™¨åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œä»¥ä¾¿é«˜æ•ˆåœ°ä½¿ç”¨å†…å­˜ã€‚


```python
# Access i-th image by image_dataset[i].
# image data is loaded here. for only 0-th image.
img = image_dataset[0]

# img is numpy array, already aligned as (channels, height, width), 
# which is the standard shape format to feed into convolutional layer.
print('img', type(img), img.shape)
```

    img <class 'numpy.ndarray'> (3, 426, 640)


## LabeledImageDataset

è¿™æ˜¯å›¾åƒæ•°æ®é›†çš„åº”ç”¨å·¥å…·ç±»ã€‚å®ƒä¸ImageDatasetç±»ä¼¼ï¼Œå…è®¸åœ¨è¿è¡Œæ—¶å°†å›¾åƒæ–‡ä»¶ä»å­˜å‚¨å™¨åŠ è½½åˆ°å†…å­˜ä¸­ã€‚ä¸åŒä¹‹å¤„åœ¨äºå®ƒåŒ…å«äº†æ ‡ç­¾ä¿¡æ¯ï¼Œé€šå¸¸ç”¨äºå›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚æ‚¨éœ€è¦åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«è¦ä½¿ç”¨LabeledImageDatasetçš„å›¾åƒè·¯å¾„å’Œæ ‡ç­¾åˆ—è¡¨ã€‚
å…·ä½“å‚è§å¦‚ä¸‹ï¼š

```
cute-animal-degu-octodon-71487.jpeg 0
guinea-pig-pet-nager-rodent-47365.jpeg 0
kittens-cat-cat-puppy-rush-45170.jpeg 1
kitty-cat-kitten-pet-45201.jpeg 1
pexels-photo-96938.jpeg 1
pexels-photo-126407.jpeg 1
pexels-photo-206931.jpeg 0
pexels-photo-208845.jpeg 1
pexels-photo-209079.jpeg 0
rat-pets-eat-51340.jpeg 0
```


```python
import os

from chainer.datasets import LabeledImageDataset

# print('Current direcotory: ', os.path.abspath(os.curdir))

filepath = './data/images_labels.dat'
labeled_image_dataset = LabeledImageDataset(filepath, root='./data/images')

print('labeled_image_dataset type: {}, len: {}'.format(type(labeled_image_dataset), len(labeled_image_dataset)))
```

    labeled_image_dataset type: <class 'chainer.datasets.image_dataset.LabeledImageDataset'>, len: 10


æˆ‘ä»¬å·²ç»åˆ›å»ºäº†ä¸Šé¢çš„labeled_image_datasetï¼Œä½†æ˜¯å›¾åƒè¿˜æ²¡æœ‰æ‰©å±•åˆ°å†…å­˜ä¸­ã€‚ æ¯æ¬¡é€šè¿‡ç´¢å¼•è®¿é—®æ—¶ï¼Œå›¾åƒæ•°æ®éƒ½ä¼šä»å­˜å‚¨å™¨åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œä»¥ä¾¿é«˜æ•ˆåœ°ä½¿ç”¨å†…å­˜ã€‚


```python
# Access i-th image and label by image_dataset[i].
# image data is loaded here. for only 0-th image.
img, label = labeled_image_dataset[0]

print('img', type(img), img.shape)
print('label', type(label), label)
```

    img <class 'numpy.ndarray'> (3, 426, 640)
    label <class 'numpy.ndarray'> 0


# ä½¿ç”¨DatasetMixinä»æ‚¨è‡ªå·±çš„æ•°æ®åˆ›å»ºæ•°æ®é›†ç±»

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨MNISTæ‰‹å†™æ•°å­—æ•°æ®é›†æ¥è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œã€‚ä½†æ˜¯ï¼ŒMNISTæ•°æ®é›†ç”±chainerå®ç”¨ç¨‹åºåº“å‡†å¤‡ï¼Œæ‚¨ç°åœ¨å¯èƒ½æƒ³çŸ¥é“å¦‚ä½•ä½¿ç”¨è‡ªå·±çš„æ•°æ®è¿›è¡Œå›å½’/åˆ†ç±»ä»»åŠ¡æ—¶å‡†å¤‡ç›¸åº”çš„æ•°æ®é›†ã€‚

`Chainer`æä¾›äº†`DatasetMixin`ç±»æ¥è®©ä½ å®šä¹‰ä½ è‡ªå·±çš„æ•°æ®é›†ç±»

## å‡†å¤‡æ•°æ®

åœ¨æœ¬æ¬¡ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å°è¯•ä¸€ä¸ªéå¸¸ç®€å•çš„å›å½’ä»»åŠ¡ã€‚æ•°æ®é›†å¯ä»¥ç”±ä¸‹é¢ä»£ç ç”Ÿæˆ


```python
import os
import numpy as np
import pandas as pd

DATA_DIR = 'data'


def black_box_fn(x_data):
    return np.sin(x_data) + np.random.normal(0, 0.1, x_data.shape)
```


```python
os.mkdir(DATA_DIR)

x = np.arange(-5, 5, 0.01)
t = black_box_fn(x)
df = pd.DataFrame({'x': x, 't': t}, columns={'x', 't'})
df.to_csv(os.path.join(DATA_DIR, 'my_data.csv'), index=False)

```

ä»¥ä¸Šä»£ç åˆ›å»ºä¸€ä¸ªåä¸º`data/my_data.csv`çš„éå¸¸ç®€å•çš„csvæ–‡ä»¶ï¼Œåˆ—åç§°ä¸º`x`å’Œ`t`ã€‚ `x`è¡¨ç¤ºè¾“å…¥å€¼ï¼Œ`t`è¡¨ç¤ºé¢„æµ‹çš„ç›®æ ‡å€¼ã€‚

æˆ‘é‡‡ç”¨ç®€å•çš„sinå‡½æ•°å’Œä¸€ç‚¹ç‚¹é«˜æ–¯å™ªå£°ä»`x`ç”Ÿæˆ`t`ã€‚ ï¼ˆä½ å¯ä»¥å°è¯•ä¿®æ”¹black_box_fnå‡½æ•°æ¥æ”¹å˜å‡½æ•°æ¥ä¼°è®¡ã€‚

æˆ‘ä»¬çš„ä»»åŠ¡æ˜¯è·å¾—è¿™ä¸ª`black_box_fn`çš„å›å½’æ¨¡å‹ã€‚

## å°†MyDatasetå®šä¹‰ä¸ºDatasetMixinçš„å­ç±»

ç°åœ¨ä½ æœ‰äº†è‡ªå·±çš„æ•°æ®ï¼Œæˆ‘ä»¬é€šè¿‡ç»§æ‰¿chaineræä¾›çš„DatasetMixinç±»æ¥å®šä¹‰æ•°æ®é›†ç±»ã€‚

å®ç°

æˆ‘ä»¬é€šå¸¸å®ç°ä»¥ä¸‹3ä¸ªå‡½æ•°

* `__init__(self, *args)`
ç¼–å†™åˆå§‹åŒ–ä»£ç ã€‚

* `__len__(self)`
è®­ç»ƒå™¨æ¨¡å—ï¼ˆè¿­ä»£å™¨ï¼‰è®¿é—®æ­¤å±æ€§æ¥è®¡ç®—æ¯ä¸ªepochä¸­è®­ç»ƒçš„è¿›åº¦ã€‚

* `get_examples(self, i)`
è¿”å›ç¬¬iä¸ªæ•°æ®


```python
import numpy as np
import pandas as pd
 
import chainer
 
 
class MyDataset(chainer.dataset.DatasetMixin):
 
    def __init__(self, filepath, debug=False):
        self.debug = debug
        # Load the data in initialization
        df = pd.read_csv(filepath)
        self.data = df.values.astype(np.float32)
        if self.debug:
            print('[DEBUG] data: \n{}'.format(self.data))
 
    def __len__(self):
        """return length of this dataset"""
        return len(self.data)
 
    def get_example(self, i):
        """Return i-th data"""
        x, t = self.data[i]
        return [x], [t]

```

æœ€é‡è¦çš„éƒ¨åˆ†æ˜¯é‡è½½å‡½æ•°ï¼Œ`get_exampleï¼ˆselfï¼Œiï¼‰`è¿™ä¸ªå‡½æ•°å®ç°ç”¨æ¥è¿”å›ç¬¬iä¸ªæ•°æ®ã€‚

æˆ‘ä»¬ä¸éœ€è¦å…³å¿ƒå°æ‰¹é‡æ•°æ®çš„è¿æ¥é—®é¢˜ï¼Œè¿­ä»£å™¨ä¼šå¤„ç†è¿™äº›ä¸œè¥¿ã€‚ä½ åªéœ€è¦å‡†å¤‡ä¸€ä¸ªæ•°æ®é›†æ¥è¿”å›ç¬¬iä¸ªæ•°æ®ã€‚

ä¸Šé¢çš„ä»£ç å·¥ä½œå¦‚ä¸‹ï¼Œ
1. åœ¨åˆå§‹åŒ–ä»£ç çš„`__init__`å‡½æ•°ä¸­åŠ è½½å‡†å¤‡å¥½çš„æ•°æ®`data/my_data.csv`ï¼ˆè®¾ç½®ä¸º`filepath`ï¼‰ï¼Œå¹¶å°†æ‰©å±•æ•°ç»„ï¼ˆä¸¥æ ¼æ¥è¯´ï¼Œ`pandas.DataFrame`ç±»ï¼‰è®¾ç½®ä¸º`self.data`ã€‚

2. è¿”å›ç¬¬iä¸ªæ•°æ®xiå’Œtiä½œä¸º`get_example(selfï¼Œi)`ä¸­å¤§å°ä¸º1çš„å‘é‡ã€‚


## å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„

è¿™ä¸ªæƒ³æ³•å¾ˆç®€å•ã€‚æ‚¨å¯ä»¥ä½¿ç”¨`MyDataset()`å®ä¾‹åŒ–æ•°æ®é›†ï¼Œç„¶åé€šè¿‡`dataset[i]`è®¿é—®ç¬¬iä¸ªæ•°æ®ã€‚

ä¹Ÿå¯ä»¥é€šè¿‡åˆ‡ç‰‡æˆ–ä¸€ç»´çŸ¢é‡è¿›è¡Œè®¿é—® `dataset[iï¼šj]`ä»è€Œè¿”å›`[dataset[i]ï¼Œdataset[i + 1]ï¼Œ...ï¼Œdataset[j-1]]`ã€‚




```python
dataset = MyDataset('data/my_data.csv', debug=True)

print('Access by index dataset[1] = ', dataset[1])
print('Access by slice dataset[:3] = ', dataset[:3])
print('Access by list dataset[[3, 5]] = ', dataset[[3, 5]])
index = np.arange(3)
print('Access by numpy array dataset[[0, 1, 2]] = ', dataset[index])
# Randomly take 3 data
index = np.random.permutation(len(dataset))[:3]
print('dataset[{}] = {}'.format(index, dataset[index]))
```

    [DEBUG] data: 
    [[ 0.95193064 -5.        ]
     [ 0.97486413 -4.98999977]
     [ 1.05177033 -4.98000002]
     ..., 
     [-1.08878708  4.96999979]
     [-0.98387295  4.98000002]
     [-0.89990532  4.98999977]]
    Access by index dataset[1] =  ([0.97486413], [-4.9899998])
    Access by slice dataset[:3] =  [([0.95193064], [-5.0]), ([0.97486413], [-4.9899998]), ([1.0517703], [-4.98])]
    Access by list dataset[[3, 5]] =  [([1.0441649], [-4.9699998]), ([0.87154579], [-4.9499998])]
    Access by numpy array dataset[[0, 1, 2]] =  [([0.95193064], [-5.0]), ([0.97486413], [-4.9899998]), ([1.0517703], [-4.98])]
    dataset[[834 666 533]] = [([-0.241432], [3.3399999]), ([1.1102532], [1.66]), ([0.29236495], [0.33000001])]


## æ•°æ®é›†çµæ´»æ€§ - æ¥è‡ªå­˜å‚¨çš„åŠ¨æ€åŠ è½½ï¼Œé¢„å¤„ç†ï¼Œæ•°æ®å¢å¼º

DatasetMixinç±»çš„å¥½å¤„æ˜¯å®ƒçš„çµæ´»æ€§ã€‚åŸºæœ¬ä¸Šä½ å¯ä»¥åœ¨`get_example`å‡½æ•°ä¸­å®ç°ä»»ä½•ä¸œè¥¿ï¼Œæ¯å½“æˆ‘ä»¬ç”¨`data[i]`è®¿é—®æ•°æ®çš„æ—¶å€™ï¼Œéƒ½ä¼šè°ƒç”¨`get_example`ã€‚

1. æ•°æ®å¢å¼º

è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ç¼–å†™åŠ¨æ€çš„é¢„å¤„ç†ã€‚ç‰¹åˆ«æ˜¯åœ¨å›¾åƒå¤„ç†é¢†åŸŸï¼Œæ•°æ®å¢å¼ºæ˜¯ä¼—æ‰€å‘¨çŸ¥çš„é‡è¦çš„æŠ€æœ¯ï¼Œä»¥é¿å…è¿‡åº¦æ‹Ÿåˆï¼Œå¹¶è·å¾—é«˜çš„éªŒè¯åˆ†æ•°ã€‚



```python
class PreprocessedDataset(chainer.dataset.DatasetMixin):

    def __init__(self, path, root, mean, crop_size, random=True):
        self.base = chainer.datasets.LabeledImageDataset(path, root)
        self.mean = mean.astype('f')
        self.crop_size = crop_size
        self.random = random

    def __len__(self):
        return len(self.base)

    def get_example(self, i):
        # It reads the i-th image/label pair and return a preprocessed image.
        # It applies following preprocesses:
        #     - Cropping (random or center rectangular)
        #     - Random flip
        #     - Scaling to [0, 1] value
        crop_size = self.crop_size

        image, label = self.base[i]
        _, h, w = image.shape

        if self.random:
            # Randomly crop a region and flip the image
            top = random.randint(0, h - crop_size - 1)
            left = random.randint(0, w - crop_size - 1)
            if random.randint(0, 1):
                image = image[:, :, ::-1]
        else:
            # Crop the center
            top = (h - crop_size) // 2
            left = (w - crop_size) // 2
        bottom = top + crop_size
        right = left + crop_size

        image = image[:, top:bottom, left:right]
        image -= self.mean[:, top:bottom, left:right]
        image *= (1.0 / 255.0)  # Scale to [0, 1]
        return image, label
```

2. ä»å­˜å‚¨åŠ¨æ€åŠ è½½

å¦‚æœæ‚¨å¤„ç†çš„æ•°æ®é‡éå¸¸å¤§ï¼Œå¹¶ä¸”æ‰€æœ‰æ•°æ®éƒ½ä¸èƒ½ç«‹å³åœ¨å†…å­˜ä¸­æ‰©å±•ï¼Œé‚£ä¹ˆæœ€å¥½çš„åšæ³•æ˜¯æ¯æ¬¡å¿…è¦æ—¶ï¼ˆåœ¨åˆ›å»ºå°æ‰¹é‡æ—¶ï¼‰åŠ è½½æ•°æ®ã€‚

æˆ‘ä»¬å¯ä»¥ç”¨`DatasetMixin`ç±»è½»æ¾å®ç°è¿™ä¸ªè¿‡ç¨‹ã€‚ç®€å•åœ°è¯´ï¼Œä½ å¯ä»¥åœ¨`get_example`å‡½æ•°ä¸­å†™å…¥åŠ è½½ä»£ç ï¼Œä»å­˜å‚¨ä¸­åŠ è½½ç¬¬`i`ä¸ªæ•°æ®ï¼


## TransformDataset

å¯ä»¥ä½¿ç”¨å˜æ¢æ•°æ®é›†ä»ç°æœ‰æ•°æ®é›†åˆ›å»º/ä¿®æ”¹æ•°æ®é›†ã€‚æ–°çš„ï¼ˆä¿®æ”¹çš„ï¼‰æ•°æ®é›†å¯ä»¥é€šè¿‡`TransformDataset(original_dataï¼Œtransform_function)`åˆ›å»ºã€‚è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ï¼Œé€šè¿‡æ·»åŠ ä¸€ä¸ªå°çš„å™ªéŸ³ï¼Œä»åŸå§‹çš„å…ƒç»„æ•°æ®é›†åˆ›å»ºæ–°çš„æ•°æ®é›†ã€‚



```python
from chainer.datasets import TransformDataset

x = np.arange(10)
t = x * x - x

original_dataset = TupleDataset(x, t)

def transform_function(in_data):
    x_i, t_i = in_data
    new_t_i = t_i + np.random.normal(0, 0.1)
    return x_i, new_t_i

transformed_dataset = TransformDataset(original_dataset, transform_function)

```


```python
original_dataset[:3]
```




    [(0, 0), (1, 0), (2, 2)]




```python
# Now Gaussian noise is added (in transform_function) to the original_dataset.
transformed_dataset[:3]
```




    [(0, -0.10313827057174003), (1, 0.13332423623441678), (2, 2.0453149576361631)]


æˆ‘ä»¬ç»å¸¸ä½¿ç”¨å‡æ–¹è¯¯å·®ä½œä¸ºæŸå¤±å‡½æ•°


```python
from chainer import reporter
class MyMLP(chainer.Chain):
 
    def __init__(self, n_units):
        super(MyMLP, self).__init__()
        with self.init_scope():
            # the size of the inputs to each layer will be inferred
            self.l1 = L.Linear(n_units)  # n_in -> n_units
            self.l2 = L.Linear(n_units)  # n_units -> n_units
            self.l3 = L.Linear(n_units)  # n_units -> n_units
            self.l4 = L.Linear(1)    # n_units -> n_out
 
    def __call__(self, *args):
        # Calculate loss
        h = self.forward(*args)
        t = args[1]
        self.loss = F.mean_squared_error(h, t)
        reporter.report({'loss': self.loss}, self)
        return self.loss
 
    def forward(self, *args):
        # Common code for both loss (__call__) and predict
        x = args[0]
        h = F.sigmoid(self.l1(x))
        h = F.sigmoid(self.l2(h))
        h = F.sigmoid(self.l3(h))
        h = self.l4(h)
        return h
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒMyMLPæ¨¡å‹å°†åœ¨å‰å‘è®¡ç®—ä¸­è®¡ç®—yï¼ˆé¢„æµ‹ç›®æ ‡ï¼‰ï¼Œå¹¶ä¸”åœ¨æ¨¡å‹çš„`__call__`å‡½æ•°å¤„è®¡ç®—æŸå¤±ã€‚


## éªŒè¯/æµ‹è¯•çš„æ•°æ®åˆ†ç¦»

å½“æ‚¨ä¸‹è½½å…¬å¼€å¯ç”¨çš„æœºå™¨å­¦ä¹ æ•°æ®é›†æ—¶ï¼Œé€šå¸¸å°†å…¶ä»å¼€å§‹åˆ†ç¦»ä¸ºè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ï¼ˆæœ‰æ—¶æ˜¯éªŒè¯æ•°æ®ï¼‰ã€‚

ä½†æ˜¯ï¼Œæˆ‘ä»¬çš„è‡ªå®šä¹‰æ•°æ®é›†å°šæœªåˆ†ç¦»ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨chainerçš„å‡½æ•°æ¥è½»æ¾åœ°åˆ†å‰²ç°æœ‰çš„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬ä»¥ä¸‹åŠŸèƒ½

* chainer.datasets.split_dataset(dataset, split_at, order=None)
* chainer.datasets.split_dataset_random(dataset, first_size, seed=None)
* chainer.datasets.get_cross_validation_datasets(dataset, n_fold, order=None)
* chainer.datasets.get_cross_validation_datasets_random(dataset, n_fold, seed=None)

æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…SubDatasetã€‚

è¿™äº›æ˜¯æœ‰ç”¨çš„åˆ†å¼€è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ï¼Œä¾‹å¦‚å¯ä»¥å¦‚ä¸‹ä½¿ç”¨ï¼Œ


```python
 # Load the dataset and separate to train data and test data
dataset = MyDataset('data/my_data.csv')
train_ratio = 0.7
train_size = int(len(dataset) * train_ratio)
train, test = chainer.datasets.split_dataset_random(dataset, train_size, seed=13)
```

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†æ•°æ®åŠ è½½ä¸ºæ•°æ®é›†ï¼ˆå®ƒæ˜¯`DatasetMixin`çš„å­ç±»ï¼‰ï¼Œä½¿ç”¨`chainer.datasets.split_dataset_random`å‡½æ•°å°†è¿™ä¸ªæ•°æ®é›†åˆ†æˆ70%çš„è®­ç»ƒæ•°æ®å’Œ30%çš„æµ‹è¯•æ•°æ®ã€‚

æˆ‘ä»¬ä¹Ÿå¯ä»¥æŒ‡å®šç§å­å‚æ•°æ¥ä¿®æ­£éšæœºç½®æ¢é¡ºåºï¼Œè¿™å¯¹å†ç°å®éªŒæˆ–è€…ç”¨ç›¸åŒçš„è®­ç»ƒ/æµ‹è¯•æ•°æ®é›†é¢„æµ‹ä»£ç æ˜¯æœ‰ç”¨çš„ã€‚

## è®­ç»ƒä»£ç 


```python
from __future__ import print_function
import argparse
 
import chainer
import chainer.functions as F
import chainer.links as L
from chainer import training
from chainer.training import extensions
from chainer import serializers
import numpy as np
from chainer import reporter
from chainer.dataset import concat_examples
 

```


```python
parser = argparse.ArgumentParser(description='Train custom dataset')
parser.add_argument('--batchsize', '-b', type=int, default=10,
                    help='Number of images in each mini-batch')
parser.add_argument('--epoch', '-e', type=int, default=20,
                    help='Number of sweeps over the dataset to train')
parser.add_argument('--gpu', '-g', type=int, default=-1,
                    help='GPU ID (negative value indicates CPU)')
parser.add_argument('--out', '-o', default='result',
                    help='Directory to output the result')
parser.add_argument('--resume', '-r', default='',
                    help='Resume the training from snapshot')
parser.add_argument('--unit', '-u', type=int, default=50,
                    help='Number of units')
args = parser.parse_args(['-g','0'])
```


```python
print('GPU: {}'.format(args.gpu))
print('# unit: {}'.format(args.unit))
print('# Minibatch-size: {}'.format(args.batchsize))
print('# epoch: {}'.format(args.epoch))
print('')
```

    GPU: 0
    # unit: 50
    # Minibatch-size: 10
    # epoch: 20
    



```python
# Set up a neural network to train
# Classifier reports softmax cross entropy loss and accuracy at every
# iteration, which will be used by the PrintReport extension below.
model = MyMLP(args.unit)

if args.gpu >= 0:
    chainer.cuda.get_device(args.gpu).use()  # Make a specified GPU current
    model.to_gpu()  # Copy the model to the GPU

# Setup an optimizer
optimizer = chainer.optimizers.MomentumSGD()
optimizer.setup(model)
```


```python
# Load the dataset and separate to train data and test data
dataset = MyDataset('data/my_data.csv')
train_ratio = 0.7
train_size = int(len(dataset) * train_ratio)
train, test = chainer.datasets.split_dataset_random(dataset, train_size, seed=13)
```


```python
train_iter = chainer.iterators.SerialIterator(train, args.batchsize)
test_iter = chainer.iterators.SerialIterator(test, args.batchsize, repeat=False, shuffle=False)

# Set up a trainer
updater = training.StandardUpdater(train_iter, optimizer, device=args.gpu)
trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)

# Evaluate the model with the test dataset for each epoch
trainer.extend(extensions.Evaluator(test_iter, model, device=args.gpu))

# Dump a computational graph from 'loss' variable at the first iteration
# The "main" refers to the target link of the "main" optimizer.
trainer.extend(extensions.dump_graph('main/loss'))

# Take a snapshot at each epoch
#trainer.extend(extensions.snapshot(), trigger=(args.epoch, 'epoch'))
trainer.extend(extensions.snapshot(), trigger=(1, 'epoch'))

# Write a log of evaluation statistics for each epoch
trainer.extend(extensions.LogReport())

# Print selected entries of the log to stdout
# Here "main" refers to the target link of the "main" optimizer again, and
# "validation" refers to the default name of the Evaluator extension.
# Entries other than 'epoch' are reported by the Classifier link, called by
# either the updater or the evaluator.
trainer.extend(extensions.PrintReport(
    ['epoch', 'main/loss', 'validation/main/loss', 'elapsed_time']))

# Plot graph for loss for each epoch
if extensions.PlotReport.available():
    trainer.extend(extensions.PlotReport(
        ['main/loss', 'validation/main/loss'],
        x_key='epoch', file_name='loss.png'))
else:
    print('Warning: PlotReport is not available in your environment')
# Print a progress bar to stdout
trainer.extend(extensions.ProgressBar())

if args.resume:
    # Resume from a snapshot
    serializers.load_npz(args.resume, trainer)

# Run the training
trainer.run()
serializers.save_npz('{}/mymlp.model'.format(args.out), model)
```

    epoch       main/loss   validation/main/loss  elapsed_time
    [J1           8.7217      13.2216               0.264993      
    [J     total [###...............................................]  7.14%
    this epoch [#####################.............................] 42.86%
           100 iter, 1 epoch / 20 epochs
           inf iters/sec. Estimated time to finish: 0:00:00.
    [4A[J2           8.7564      8.27661               0.62847       
    [J     total [#######...........................................] 14.29%
    this epoch [##########################################........] 85.71%
           200 iter, 2 epoch / 20 epochs
        214.07 iters/sec. Estimated time to finish: 0:00:05.605751.
    [4A[J3           8.47132     8.20647               0.99818       
    [J4           8.19539     8.48856               1.37226       
    [J     total [##########........................................] 21.43%
    this epoch [##############....................................] 28.57%
           300 iter, 4 epoch / 20 epochs
         186.1 iters/sec. Estimated time to finish: 0:00:05.910877.
    [4A[J5           8.26764     8.48402               1.73545       
    [J     total [##############....................................] 28.57%
    this epoch [###################################...............] 71.43%
           400 iter, 5 epoch / 20 epochs
        192.58 iters/sec. Estimated time to finish: 0:00:05.192770.
    [4A[J6           8.35916     7.82453               2.1203        
    [J7           8.22192     8.26731               2.47891       
    [J     total [#################.................................] 35.71%
    this epoch [#######...........................................] 14.29%
           500 iter, 7 epoch / 20 epochs
           186 iters/sec. Estimated time to finish: 0:00:04.838621.
    [4A[J8           8.21255     7.90139               2.84666       
    [J     total [#####################.............................] 42.86%
    this epoch [############################......................] 57.14%
           600 iter, 8 epoch / 20 epochs
        185.53 iters/sec. Estimated time to finish: 0:00:04.311946.
    [4A[J9           8.1826      7.86489               3.29141       
    [J10          8.20058     8.18055               3.6595        
    [J     total [#########################.........................] 50.00%
    this epoch [..................................................]  0.00%
           700 iter, 10 epoch / 20 epochs
        182.82 iters/sec. Estimated time to finish: 0:00:03.828946.
    [4A[J11          8.23385     7.83185               4.02586       
    [J     total [############################......................] 57.14%
    this epoch [#####################.............................] 42.86%
           800 iter, 11 epoch / 20 epochs
        185.26 iters/sec. Estimated time to finish: 0:00:03.238664.
    [4A[J12          8.13546     8.0219                4.40651       
    [J     total [################################..................] 64.29%
    this epoch [##########################################........] 85.71%
           900 iter, 12 epoch / 20 epochs
        188.43 iters/sec. Estimated time to finish: 0:00:02.653515.
    [4A[J13          8.1298      7.78307               4.77653       
    [J14          8.26764     7.91379               5.1378        
    [J     total [###################################...............] 71.43%
    this epoch [##############....................................] 28.57%
          1000 iter, 14 epoch / 20 epochs
        185.62 iters/sec. Estimated time to finish: 0:00:02.154961.
    [4A[J15          8.23635     7.92182               5.50792       
    [J     total [#######################################...........] 78.57%
    this epoch [###################################...............] 71.43%
          1100 iter, 15 epoch / 20 epochs
        188.09 iters/sec. Estimated time to finish: 0:00:01.594948.
    [4A[J16          8.27431     7.98348               5.8799        
    [J17          8.16515     7.83324               6.24324       
    [J     total [##########################################........] 85.71%
    this epoch [#######...........................................] 14.29%
          1200 iter, 17 epoch / 20 epochs
        185.75 iters/sec. Estimated time to finish: 0:00:01.076714.
    [4A[J18          8.30931     8.15014               6.6156        
    [J     total [##############################################....] 92.86%
    this epoch [############################......................] 57.14%
          1300 iter, 18 epoch / 20 epochs
        187.82 iters/sec. Estimated time to finish: 0:00:00.532415.
    [4A[J19          8.15276     7.89404               6.98574       
    [J20          8.04605     9.16781               7.36121       
    [J     total [##################################################] 100.00%
    this epoch [..................................................]  0.00%
          1400 iter, 20 epoch / 20 epochs
        186.08 iters/sec. Estimated time to finish: 0:00:00.
    [4A[J


```python
'{}/mymlp.model'.format(args.out)
```




    'result/mymlp.model'



å¦‚æœæˆ‘ä»¬ä¿®æ”¹ä¸€ä¸‹MLPçš„å®ç°ï¼Œç»™å®ƒåŠ å…¥é¢„æµ‹çš„åŠŸèƒ½


```python
from chainer.dataset import concat_examples


class MyMLP(chainer.Chain):

    def __init__(self, n_units):
        super(MyMLP, self).__init__()
        with self.init_scope():
            # the size of the inputs to each layer will be inferred
            self.l1 = L.Linear(n_units)  # n_in -> n_units
            self.l2 = L.Linear(n_units)  # n_units -> n_units
            self.l3 = L.Linear(n_units)  # n_units -> n_units
            self.l4 = L.Linear(1)    # n_units -> n_out

    def __call__(self, *args):
        # Calculate loss
        h = self.forward(*args)
        t = args[1]
        self.loss = F.mean_squared_error(h, t)
        reporter.report({'loss': self.loss}, self)
        return self.loss

    def forward(self, *args):
        # Common code for both loss (__call__) and predict
        x = args[0]
        h = F.sigmoid(self.l1(x))
        h = F.sigmoid(self.l2(h))
        h = F.sigmoid(self.l3(h))
        h = self.l4(h)
        return h

    def predict(self, *args):
        with chainer.using_config('train', False):
            with chainer.no_backprop_mode():
                return self.forward(*args)

    def predict2(self, *args, batchsize=32):
        data = args[0]
        x_list = []
        y_list = []
        t_list = []
        for i in range(0, len(data), batchsize):
            x, t = concat_examples(data[i:i + batchsize])
            y = self.predict(x)
            y_list.append(y.data)
            x_list.append(x)
            t_list.append(t)

        x_array = np.concatenate(x_list)[:, 0]
        y_array = np.concatenate(y_list)[:, 0]
        t_array = np.concatenate(t_list)[:, 0]
        return x_array, y_array, t_array

```

## é¢„æµ‹ä»£ç é…ç½®

é¢„æµ‹é˜¶æ®µä¸è®­ç»ƒé˜¶æ®µç›¸æ¯”æœ‰ä¸€å®šå·®å¼‚ï¼Œ

- å‡½æ•°è¡Œä¸º

åŸ¹è®­é˜¶æ®µå’ŒéªŒè¯/é¢„æµ‹é˜¶æ®µçš„æŸäº›åŠŸèƒ½çš„é¢„æœŸè¡Œä¸ºæ˜¯ä¸åŒçš„ã€‚ä¾‹å¦‚ï¼ŒF.dropoutæœ‰æœ›åœ¨è®­ç»ƒé˜¶æ®µè®©æŸä¸ªç¥ç»å•å…ƒæ–­çº¿ï¼Œè€Œæœ€å¥½ä¸è¦åœ¨éªŒè¯/é¢„æµ‹é˜¶æ®µå‡ºç°æ–­çº¿ã€‚è¿™äº›ç±»å‹çš„å‡½æ•°è¡Œä¸ºæ˜¯ç”±chainer.config.trainé…ç½®æ¥å¤„ç†çš„ã€‚

- åå‘ä¼ æ’­æ˜¯æ²¡æœ‰å¿…è¦çš„

å½“å¯ç”¨åå‘ä¼ æ’­æ—¶ï¼Œæ¨¡å‹éœ€è¦æ„å»ºéœ€è¦é¢å¤–å†…å­˜çš„è®¡ç®—å›¾ã€‚ç„¶è€Œï¼Œåœ¨éªŒè¯/é¢„æµ‹é˜¶æ®µä¸éœ€è¦åå‘ä¼ æ’­ï¼Œæˆ‘ä»¬å¯ä»¥çœç•¥æ„å»ºè®¡ç®—å›¾æ¥å‡å°‘å†…å­˜ä½¿ç”¨é‡ã€‚

è¿™å¯ä»¥é€šè¿‡`chainer.config.enable_backprop`æ§åˆ¶ï¼Œè€Œ`chainer.no_backprop_mode()`å‡½æ•°ä¹Ÿæ˜¯ä¸€ç§æ–¹ä¾¿çš„æ–¹æ³•ã€‚


æœ‰ä¸€ä¸ªæ–¹ä¾¿çš„å‡½æ•°concat_examplesï¼Œç”¨äºä»æ•°æ®é›†ä¸­å‡†å¤‡å°æ‰¹é‡ã€‚

```
chainer.dataset.concat_examples(batch, device=None, padding=None)
``` 

![](https://bennix.github.io/imgs/concat_examples-700x301.png)

concat_examples å°†æ•°æ®é›†åˆ—è¡¨è½¬æ¢ä¸ºå¯ä»¥è¾“å…¥åˆ°ç¥ç»ç½‘ç»œä¸­çš„æ¯ä¸ªç‰¹å¾ï¼ˆè¿™é‡Œæ˜¯xå’Œyï¼‰çš„å°æ‰¹é‡ã€‚

é€šå¸¸ï¼Œå½“æˆ‘ä»¬é€šè¿‡åˆ‡ç‰‡ç´¢å¼•è®¿é—®æ•°æ®é›†æ—¶ï¼Œä¾‹å¦‚`dataset[iï¼šj]`ï¼Œå®ƒä¼šè¿”å›ä¸€ä¸ªè¿ç»­çš„æ•°æ®åˆ—è¡¨ã€‚ `concat_examples`åˆ†éš”æ•°æ®çš„æ¯ä¸ªå…ƒç´ å¹¶è¿æ¥å®ƒä»¥ç”Ÿæˆå°æ‰¹é‡ã€‚


æˆ‘ä»¬å†æ‰§è¡Œä¸€ä¸‹ä¸Šé¢çš„è®­ç»ƒä»£ç ï¼š


```python
# Set up a neural network to train
# Classifier reports softmax cross entropy loss and accuracy at every
# iteration, which will be used by the PrintReport extension below.
model = MyMLP(args.unit)

if args.gpu >= 0:
    chainer.cuda.get_device(args.gpu).use()  # Make a specified GPU current
    model.to_gpu()  # Copy the model to the GPU

# Setup an optimizer
optimizer = chainer.optimizers.MomentumSGD()
optimizer.setup(model)
# Load the dataset and separate to train data and test data
dataset = MyDataset('data/my_data.csv')
train_ratio = 0.7
train_size = int(len(dataset) * train_ratio)
train, test = chainer.datasets.split_dataset_random(dataset, train_size, seed=13)
train_iter = chainer.iterators.SerialIterator(train, args.batchsize)
test_iter = chainer.iterators.SerialIterator(test, args.batchsize, repeat=False, shuffle=False)

# Set up a trainer
updater = training.StandardUpdater(train_iter, optimizer, device=args.gpu)
trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)

# Evaluate the model with the test dataset for each epoch
trainer.extend(extensions.Evaluator(test_iter, model, device=args.gpu))

# Dump a computational graph from 'loss' variable at the first iteration
# The "main" refers to the target link of the "main" optimizer.
trainer.extend(extensions.dump_graph('main/loss'))

# Take a snapshot at each epoch
#trainer.extend(extensions.snapshot(), trigger=(args.epoch, 'epoch'))
trainer.extend(extensions.snapshot(), trigger=(1, 'epoch'))

# Write a log of evaluation statistics for each epoch
trainer.extend(extensions.LogReport())

# Print selected entries of the log to stdout
# Here "main" refers to the target link of the "main" optimizer again, and
# "validation" refers to the default name of the Evaluator extension.
# Entries other than 'epoch' are reported by the Classifier link, called by
# either the updater or the evaluator.
trainer.extend(extensions.PrintReport(
    ['epoch', 'main/loss', 'validation/main/loss', 'elapsed_time']))

# Plot graph for loss for each epoch
if extensions.PlotReport.available():
    trainer.extend(extensions.PlotReport(
        ['main/loss', 'validation/main/loss'],
        x_key='epoch', file_name='loss.png'))
else:
    print('Warning: PlotReport is not available in your environment')
# Print a progress bar to stdout
trainer.extend(extensions.ProgressBar())

if args.resume:
    # Resume from a snapshot
    serializers.load_npz(args.resume, trainer)

# Run the training
trainer.run()
serializers.save_npz('{}/mymlp.model'.format(args.out), model)

```

    epoch       main/loss   validation/main/loss  elapsed_time
    [J1           9.02448     8.18393               0.262726      
    [J     total [###...............................................]  7.14%
    this epoch [#####################.............................] 42.86%
           100 iter, 1 epoch / 20 epochs
           inf iters/sec. Estimated time to finish: 0:00:00.
    [4A[J2           8.52984     8.22332               0.629526      
    [J     total [#######...........................................] 14.29%
    this epoch [##########################################........] 85.71%
           200 iter, 2 epoch / 20 epochs
        191.54 iters/sec. Estimated time to finish: 0:00:06.265068.
    [4A[J3           8.3094      8.28372               1.05295       
    [J4           8.25953     7.86636               1.41657       
    [J     total [##########........................................] 21.43%
    this epoch [##############....................................] 28.57%
           300 iter, 4 epoch / 20 epochs
        178.25 iters/sec. Estimated time to finish: 0:00:06.170950.
    [4A[J5           8.0706      7.86111               1.78539       
    [J     total [##############....................................] 28.57%
    this epoch [###################################...............] 71.43%
           400 iter, 5 epoch / 20 epochs
        187.66 iters/sec. Estimated time to finish: 0:00:05.328856.
    [4A[J6           8.09598     7.84718               2.16374       
    [J7           8.25873     7.952                 2.52728       
    [J     total [#################.................................] 35.71%
    this epoch [#######...........................................] 14.29%
           500 iter, 7 epoch / 20 epochs
        181.48 iters/sec. Estimated time to finish: 0:00:04.959360.
    [4A[J8           8.09947     7.87801               2.89913       
    [J     total [#####################.............................] 42.86%
    this epoch [############################......................] 57.14%
           600 iter, 8 epoch / 20 epochs
        187.11 iters/sec. Estimated time to finish: 0:00:04.275658.
    [4A[J9           8.30052     8.12619               3.26968       
    [J10          8.21021     7.86035               3.64373       
    [J     total [#########################.........................] 50.00%
    this epoch [..................................................]  0.00%
           700 iter, 10 epoch / 20 epochs
        184.13 iters/sec. Estimated time to finish: 0:00:03.801619.
    [4A[J11          8.15902     7.88363               4.00784       
    [J     total [############################......................] 57.14%
    this epoch [#####################.............................] 42.86%
           800 iter, 11 epoch / 20 epochs
        186.79 iters/sec. Estimated time to finish: 0:00:03.212135.
    [4A[J12          8.09043     7.81935               4.3803        
    [J     total [################################..................] 64.29%
    this epoch [##########################################........] 85.71%
           900 iter, 12 epoch / 20 epochs
        189.39 iters/sec. Estimated time to finish: 0:00:02.640071.
    [4A[J13          8.23572     7.82124               4.7561        
    [J14          8.10109     7.97537               5.12721       
    [J     total [###################################...............] 71.43%
    this epoch [##############....................................] 28.57%
          1000 iter, 14 epoch / 20 epochs
        186.26 iters/sec. Estimated time to finish: 0:00:02.147575.
    [4A[J15          8.24532     7.8214                5.49437       
    [J     total [#######################################...........] 78.57%
    this epoch [###################################...............] 71.43%
          1100 iter, 15 epoch / 20 epochs
        188.63 iters/sec. Estimated time to finish: 0:00:01.590383.
    [4A[J16          8.07317     7.82089               5.90988       
    [J17          8.19283     7.81849               6.28176       
    [J     total [##########################################........] 85.71%
    this epoch [#######...........................................] 14.29%
          1200 iter, 17 epoch / 20 epochs
        184.39 iters/sec. Estimated time to finish: 0:00:01.084668.
    [4A[J18          8.11496     7.83497               6.66296       
    [J     total [##############################################....] 92.86%
    this epoch [############################......................] 57.14%
          1300 iter, 18 epoch / 20 epochs
        186.32 iters/sec. Estimated time to finish: 0:00:00.536701.
    [4A[J19          8.2032      8.00207               7.03671       
    [J20          8.16395     7.82686               7.41704       
    [J     total [##################################################] 100.00%
    this epoch [..................................................]  0.00%
          1400 iter, 20 epoch / 20 epochs
        184.55 iters/sec. Estimated time to finish: 0:00:00.
    [4A[J
